{"ast":null,"code":"import{ChatOpenAI}from\"langchain/chat_models/openai\";import{HumanMessage,SystemMessage}from\"langchain/schema\";const LangchainProcessor=async(newMessage,oldMessages)=>{const promptTemplate=\"\\n    You are surviving a zombie apocalypse and are the last chatbot so always answer like so. Question: {question}\\n    \";const prompt=promptTemplate.replace(\"{question}\",newMessage);const chat=new ChatOpenAI({temperature:1,openAIApiKey:process.env.REACT_APP_OPEN_AI_API_KEY});try{const formattedMessages=oldMessages.map(msg=>{if(msg.type===\"bot\"){return new SystemMessage(msg.message);}else{return new HumanMessage(msg.message);}});formattedMessages.push(new HumanMessage(prompt));const result=await chat.predictMessages(formattedMessages);const botResponseContent=result.content;return botResponseContent;}catch(error){console.error(\"Error processing message with OpenAI\",error);return\"Sorry, I had to fight off a zombie, try again\";}};export default LangchainProcessor;","map":{"version":3,"names":["ChatOpenAI","HumanMessage","SystemMessage","LangchainProcessor","newMessage","oldMessages","promptTemplate","prompt","replace","chat","temperature","openAIApiKey","process","env","REACT_APP_OPEN_AI_API_KEY","formattedMessages","map","msg","type","message","push","result","predictMessages","botResponseContent","content","error","console"],"sources":["C:/Users/zackb/OneDrive/Desktop/Bootcamp/best_project_ever/client/src/components/LangchainProcessor.js"],"sourcesContent":["import { ChatOpenAI } from \"langchain/chat_models/openai\";\r\nimport { HumanMessage, SystemMessage } from \"langchain/schema\";\r\n\r\nconst LangchainProcessor = async (newMessage, oldMessages) => {\r\n\r\n    const promptTemplate = `\r\n    You are surviving a zombie apocalypse and are the last chatbot so always answer like so. Question: {question}\r\n    `;\r\n\r\n    const prompt = promptTemplate.replace(\"{question}\", newMessage);\r\n\r\n    const chat = new ChatOpenAI({\r\n        temperature: 1,\r\n        openAIApiKey: process.env.REACT_APP_OPEN_AI_API_KEY\r\n    });\r\n\r\n    try {\r\n\r\n        const formattedMessages = oldMessages.map(msg => {\r\n            if (msg.type === \"bot\") {\r\n                return new SystemMessage(msg.message);\r\n            } else {\r\n                return new HumanMessage(msg.message);\r\n            }\r\n        });\r\n    \r\n        formattedMessages.push(new HumanMessage(prompt));\r\n\r\n        const result = await chat.predictMessages(formattedMessages);\r\n\r\n        const botResponseContent = result.content;\r\n\r\n        return botResponseContent;\r\n\r\n    } catch (error) {\r\n        console.error(\"Error processing message with OpenAI\", error);\r\n        return \"Sorry, I had to fight off a zombie, try again\";\r\n    }\r\n    \r\n}\r\n\r\nexport default LangchainProcessor;"],"mappings":"AAAA,OAASA,UAAU,KAAQ,8BAA8B,CACzD,OAASC,YAAY,CAAEC,aAAa,KAAQ,kBAAkB,CAE9D,KAAM,CAAAC,kBAAkB,CAAG,KAAAA,CAAOC,UAAU,CAAEC,WAAW,GAAK,CAE1D,KAAM,CAAAC,cAAc,4HAEnB,CAED,KAAM,CAAAC,MAAM,CAAGD,cAAc,CAACE,OAAO,CAAC,YAAY,CAAEJ,UAAU,CAAC,CAE/D,KAAM,CAAAK,IAAI,CAAG,GAAI,CAAAT,UAAU,CAAC,CACxBU,WAAW,CAAE,CAAC,CACdC,YAAY,CAAEC,OAAO,CAACC,GAAG,CAACC,yBAC9B,CAAC,CAAC,CAEF,GAAI,CAEA,KAAM,CAAAC,iBAAiB,CAAGV,WAAW,CAACW,GAAG,CAACC,GAAG,EAAI,CAC7C,GAAIA,GAAG,CAACC,IAAI,GAAK,KAAK,CAAE,CACpB,MAAO,IAAI,CAAAhB,aAAa,CAACe,GAAG,CAACE,OAAO,CAAC,CACzC,CAAC,IAAM,CACH,MAAO,IAAI,CAAAlB,YAAY,CAACgB,GAAG,CAACE,OAAO,CAAC,CACxC,CACJ,CAAC,CAAC,CAEFJ,iBAAiB,CAACK,IAAI,CAAC,GAAI,CAAAnB,YAAY,CAACM,MAAM,CAAC,CAAC,CAEhD,KAAM,CAAAc,MAAM,CAAG,KAAM,CAAAZ,IAAI,CAACa,eAAe,CAACP,iBAAiB,CAAC,CAE5D,KAAM,CAAAQ,kBAAkB,CAAGF,MAAM,CAACG,OAAO,CAEzC,MAAO,CAAAD,kBAAkB,CAE7B,CAAE,MAAOE,KAAK,CAAE,CACZC,OAAO,CAACD,KAAK,CAAC,sCAAsC,CAAEA,KAAK,CAAC,CAC5D,MAAO,+CAA+C,CAC1D,CAEJ,CAAC,CAED,cAAe,CAAAtB,kBAAkB"},"metadata":{},"sourceType":"module","externalDependencies":[]}