{"ast":null,"code":"import { AIMessage, HumanMessage, RUN_KEY } from \"../schema/index.js\";\nimport { BaseLanguageModel } from \"../base_language/index.js\";\nimport { CallbackManager } from \"../callbacks/manager.js\";\nexport function createChatMessageChunkEncoderStream() {\n  const textEncoder = new TextEncoder();\n  return new TransformStream({\n    transform(chunk, controller) {\n      controller.enqueue(textEncoder.encode(chunk.content));\n    }\n  });\n}\nexport class BaseChatModel extends BaseLanguageModel {\n  constructor(fields) {\n    super(fields);\n    Object.defineProperty(this, \"lc_namespace\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: [\"langchain\", \"chat_models\", this._llmType()]\n    });\n  }\n  _separateRunnableConfigFromCallOptions(options) {\n    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);\n    if (callOptions !== null && callOptions !== void 0 && callOptions.timeout && !callOptions.signal) {\n      callOptions.signal = AbortSignal.timeout(callOptions.timeout);\n    }\n    return [runnableConfig, callOptions];\n  }\n  async invoke(input, options) {\n    const promptValue = BaseChatModel._convertInputToPromptValue(input);\n    const result = await this.generatePrompt([promptValue], options, options === null || options === void 0 ? void 0 : options.callbacks);\n    const chatGeneration = result.generations[0][0];\n    // TODO: Remove cast after figuring out inheritance\n    return chatGeneration.message;\n  }\n  // eslint-disable-next-line require-yield\n  async *_streamResponseChunks(_messages, _options, _runManager) {\n    throw new Error(\"Not implemented.\");\n  }\n  async *_streamIterator(input, options) {\n    // Subclass check required to avoid double callbacks with default implementation\n    if (this._streamResponseChunks === BaseChatModel.prototype._streamResponseChunks) {\n      yield this.invoke(input, options);\n    } else {\n      const prompt = BaseChatModel._convertInputToPromptValue(input);\n      const messages = prompt.toChatMessages();\n      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptions(options);\n      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, {\n        verbose: this.verbose\n      });\n      const extra = {\n        options: callOptions,\n        invocation_params: this === null || this === void 0 ? void 0 : this.invocationParams(callOptions)\n      };\n      const runManagers = await (callbackManager_ === null || callbackManager_ === void 0 ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), [messages], undefined, undefined, extra));\n      let generationChunk;\n      try {\n        for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers === null || runManagers === void 0 ? void 0 : runManagers[0])) {\n          yield chunk.message;\n          if (!generationChunk) {\n            generationChunk = chunk;\n          } else {\n            generationChunk = generationChunk.concat(chunk);\n          }\n        }\n      } catch (err) {\n        await Promise.all((runManagers !== null && runManagers !== void 0 ? runManagers : []).map(runManager => runManager === null || runManager === void 0 ? void 0 : runManager.handleLLMError(err)));\n        throw err;\n      }\n      await Promise.all((runManagers !== null && runManagers !== void 0 ? runManagers : []).map(runManager => runManager === null || runManager === void 0 ? void 0 : runManager.handleLLMEnd({\n        // TODO: Remove cast after figuring out inheritance\n        generations: [[generationChunk]]\n      })));\n    }\n  }\n  async generate(messages, options, callbacks) {\n    var _runnableConfig$callb, _this$_combineLLMOutp;\n    // parse call options\n    let parsedOptions;\n    if (Array.isArray(options)) {\n      parsedOptions = {\n        stop: options\n      };\n    } else {\n      parsedOptions = options;\n    }\n    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptions(parsedOptions);\n    // create callback manager and start run\n    const callbackManager_ = await CallbackManager.configure((_runnableConfig$callb = runnableConfig.callbacks) !== null && _runnableConfig$callb !== void 0 ? _runnableConfig$callb : callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, {\n      verbose: this.verbose\n    });\n    const extra = {\n      options: callOptions,\n      invocation_params: this === null || this === void 0 ? void 0 : this.invocationParams(parsedOptions)\n    };\n    const runManagers = await (callbackManager_ === null || callbackManager_ === void 0 ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), messages, undefined, undefined, extra));\n    // generate results\n    const results = await Promise.allSettled(messages.map((messageList, i) => this._generate(messageList, {\n      ...callOptions,\n      promptIndex: i\n    }, runManagers === null || runManagers === void 0 ? void 0 : runManagers[i])));\n    // handle results\n    const generations = [];\n    const llmOutputs = [];\n    await Promise.all(results.map(async (pResult, i) => {\n      if (pResult.status === \"fulfilled\") {\n        var _runManagers$i;\n        const result = pResult.value;\n        generations[i] = result.generations;\n        llmOutputs[i] = result.llmOutput;\n        return runManagers === null || runManagers === void 0 || (_runManagers$i = runManagers[i]) === null || _runManagers$i === void 0 ? void 0 : _runManagers$i.handleLLMEnd({\n          generations: [result.generations],\n          llmOutput: result.llmOutput\n        });\n      } else {\n        var _runManagers$i2;\n        // status === \"rejected\"\n        await (runManagers === null || runManagers === void 0 || (_runManagers$i2 = runManagers[i]) === null || _runManagers$i2 === void 0 ? void 0 : _runManagers$i2.handleLLMError(pResult.reason));\n        return Promise.reject(pResult.reason);\n      }\n    }));\n    // create combined output\n    const output = {\n      generations,\n      llmOutput: llmOutputs.length ? (_this$_combineLLMOutp = this._combineLLMOutput) === null || _this$_combineLLMOutp === void 0 ? void 0 : _this$_combineLLMOutp.call(this, ...llmOutputs) : undefined\n    };\n    Object.defineProperty(output, RUN_KEY, {\n      value: runManagers ? {\n        runIds: runManagers === null || runManagers === void 0 ? void 0 : runManagers.map(manager => manager.runId)\n      } : undefined,\n      configurable: true\n    });\n    return output;\n  }\n  /**\n   * Get the parameters used to invoke the model\n   */\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  invocationParams(_options) {\n    return {};\n  }\n  _modelType() {\n    return \"base_chat_model\";\n  }\n  async generatePrompt(promptValues, options, callbacks) {\n    const promptMessages = promptValues.map(promptValue => promptValue.toChatMessages());\n    return this.generate(promptMessages, options, callbacks);\n  }\n  async call(messages, options, callbacks) {\n    const result = await this.generate([messages], options, callbacks);\n    const generations = result.generations;\n    return generations[0][0].message;\n  }\n  async callPrompt(promptValue, options, callbacks) {\n    const promptMessages = promptValue.toChatMessages();\n    return this.call(promptMessages, options, callbacks);\n  }\n  async predictMessages(messages, options, callbacks) {\n    return this.call(messages, options, callbacks);\n  }\n  async predict(text, options, callbacks) {\n    const message = new HumanMessage(text);\n    const result = await this.call([message], options, callbacks);\n    return result.content;\n  }\n}\nexport class SimpleChatModel extends BaseChatModel {\n  async _generate(messages, options, runManager) {\n    const text = await this._call(messages, options, runManager);\n    const message = new AIMessage(text);\n    return {\n      generations: [{\n        text: message.content,\n        message\n      }]\n    };\n  }\n}","map":{"version":3,"names":["AIMessage","HumanMessage","RUN_KEY","BaseLanguageModel","CallbackManager","createChatMessageChunkEncoderStream","textEncoder","TextEncoder","TransformStream","transform","chunk","controller","enqueue","encode","content","BaseChatModel","constructor","fields","Object","defineProperty","enumerable","configurable","writable","value","_llmType","_separateRunnableConfigFromCallOptions","options","runnableConfig","callOptions","timeout","signal","AbortSignal","invoke","input","promptValue","_convertInputToPromptValue","result","generatePrompt","callbacks","chatGeneration","generations","message","_streamResponseChunks","_messages","_options","_runManager","Error","_streamIterator","prototype","prompt","messages","toChatMessages","callbackManager_","configure","tags","metadata","verbose","extra","invocation_params","invocationParams","runManagers","handleChatModelStart","toJSON","undefined","generationChunk","concat","err","Promise","all","map","runManager","handleLLMError","handleLLMEnd","generate","_runnableConfig$callb","_this$_combineLLMOutp","parsedOptions","Array","isArray","stop","results","allSettled","messageList","i","_generate","promptIndex","llmOutputs","pResult","status","_runManagers$i","llmOutput","_runManagers$i2","reason","reject","output","length","_combineLLMOutput","call","runIds","manager","runId","_modelType","promptValues","promptMessages","callPrompt","predictMessages","predict","text","SimpleChatModel","_call"],"sources":["C:/Users/zackb/OneDrive/Desktop/Bootcamp/best_project_ever/client/node_modules/langchain/dist/chat_models/base.js"],"sourcesContent":["import { AIMessage, HumanMessage, RUN_KEY, } from \"../schema/index.js\";\nimport { BaseLanguageModel, } from \"../base_language/index.js\";\nimport { CallbackManager, } from \"../callbacks/manager.js\";\nexport function createChatMessageChunkEncoderStream() {\n    const textEncoder = new TextEncoder();\n    return new TransformStream({\n        transform(chunk, controller) {\n            controller.enqueue(textEncoder.encode(chunk.content));\n        },\n    });\n}\nexport class BaseChatModel extends BaseLanguageModel {\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"chat_models\", this._llmType()]\n        });\n    }\n    _separateRunnableConfigFromCallOptions(options) {\n        const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);\n        if (callOptions?.timeout && !callOptions.signal) {\n            callOptions.signal = AbortSignal.timeout(callOptions.timeout);\n        }\n        return [runnableConfig, callOptions];\n    }\n    async invoke(input, options) {\n        const promptValue = BaseChatModel._convertInputToPromptValue(input);\n        const result = await this.generatePrompt([promptValue], options, options?.callbacks);\n        const chatGeneration = result.generations[0][0];\n        // TODO: Remove cast after figuring out inheritance\n        return chatGeneration.message;\n    }\n    // eslint-disable-next-line require-yield\n    async *_streamResponseChunks(_messages, _options, _runManager) {\n        throw new Error(\"Not implemented.\");\n    }\n    async *_streamIterator(input, options) {\n        // Subclass check required to avoid double callbacks with default implementation\n        if (this._streamResponseChunks ===\n            BaseChatModel.prototype._streamResponseChunks) {\n            yield this.invoke(input, options);\n        }\n        else {\n            const prompt = BaseChatModel._convertInputToPromptValue(input);\n            const messages = prompt.toChatMessages();\n            const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptions(options);\n            const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });\n            const extra = {\n                options: callOptions,\n                invocation_params: this?.invocationParams(callOptions),\n            };\n            const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), [messages], undefined, undefined, extra);\n            let generationChunk;\n            try {\n                for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers?.[0])) {\n                    yield chunk.message;\n                    if (!generationChunk) {\n                        generationChunk = chunk;\n                    }\n                    else {\n                        generationChunk = generationChunk.concat(chunk);\n                    }\n                }\n            }\n            catch (err) {\n                await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));\n                throw err;\n            }\n            await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({\n                // TODO: Remove cast after figuring out inheritance\n                generations: [[generationChunk]],\n            })));\n        }\n    }\n    async generate(messages, options, callbacks) {\n        // parse call options\n        let parsedOptions;\n        if (Array.isArray(options)) {\n            parsedOptions = { stop: options };\n        }\n        else {\n            parsedOptions = options;\n        }\n        const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptions(parsedOptions);\n        // create callback manager and start run\n        const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks ?? callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });\n        const extra = {\n            options: callOptions,\n            invocation_params: this?.invocationParams(parsedOptions),\n        };\n        const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), messages, undefined, undefined, extra);\n        // generate results\n        const results = await Promise.allSettled(messages.map((messageList, i) => this._generate(messageList, { ...callOptions, promptIndex: i }, runManagers?.[i])));\n        // handle results\n        const generations = [];\n        const llmOutputs = [];\n        await Promise.all(results.map(async (pResult, i) => {\n            if (pResult.status === \"fulfilled\") {\n                const result = pResult.value;\n                generations[i] = result.generations;\n                llmOutputs[i] = result.llmOutput;\n                return runManagers?.[i]?.handleLLMEnd({\n                    generations: [result.generations],\n                    llmOutput: result.llmOutput,\n                });\n            }\n            else {\n                // status === \"rejected\"\n                await runManagers?.[i]?.handleLLMError(pResult.reason);\n                return Promise.reject(pResult.reason);\n            }\n        }));\n        // create combined output\n        const output = {\n            generations,\n            llmOutput: llmOutputs.length\n                ? this._combineLLMOutput?.(...llmOutputs)\n                : undefined,\n        };\n        Object.defineProperty(output, RUN_KEY, {\n            value: runManagers\n                ? { runIds: runManagers?.map((manager) => manager.runId) }\n                : undefined,\n            configurable: true,\n        });\n        return output;\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    invocationParams(_options) {\n        return {};\n    }\n    _modelType() {\n        return \"base_chat_model\";\n    }\n    async generatePrompt(promptValues, options, callbacks) {\n        const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());\n        return this.generate(promptMessages, options, callbacks);\n    }\n    async call(messages, options, callbacks) {\n        const result = await this.generate([messages], options, callbacks);\n        const generations = result.generations;\n        return generations[0][0].message;\n    }\n    async callPrompt(promptValue, options, callbacks) {\n        const promptMessages = promptValue.toChatMessages();\n        return this.call(promptMessages, options, callbacks);\n    }\n    async predictMessages(messages, options, callbacks) {\n        return this.call(messages, options, callbacks);\n    }\n    async predict(text, options, callbacks) {\n        const message = new HumanMessage(text);\n        const result = await this.call([message], options, callbacks);\n        return result.content;\n    }\n}\nexport class SimpleChatModel extends BaseChatModel {\n    async _generate(messages, options, runManager) {\n        const text = await this._call(messages, options, runManager);\n        const message = new AIMessage(text);\n        return {\n            generations: [\n                {\n                    text: message.content,\n                    message,\n                },\n            ],\n        };\n    }\n}\n"],"mappings":"AAAA,SAASA,SAAS,EAAEC,YAAY,EAAEC,OAAO,QAAS,oBAAoB;AACtE,SAASC,iBAAiB,QAAS,2BAA2B;AAC9D,SAASC,eAAe,QAAS,yBAAyB;AAC1D,OAAO,SAASC,mCAAmCA,CAAA,EAAG;EAClD,MAAMC,WAAW,GAAG,IAAIC,WAAW,CAAC,CAAC;EACrC,OAAO,IAAIC,eAAe,CAAC;IACvBC,SAASA,CAACC,KAAK,EAAEC,UAAU,EAAE;MACzBA,UAAU,CAACC,OAAO,CAACN,WAAW,CAACO,MAAM,CAACH,KAAK,CAACI,OAAO,CAAC,CAAC;IACzD;EACJ,CAAC,CAAC;AACN;AACA,OAAO,MAAMC,aAAa,SAASZ,iBAAiB,CAAC;EACjDa,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAACA,MAAM,CAAC;IACbC,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,CAAC,WAAW,EAAE,aAAa,EAAE,IAAI,CAACC,QAAQ,CAAC,CAAC;IACvD,CAAC,CAAC;EACN;EACAC,sCAAsCA,CAACC,OAAO,EAAE;IAC5C,MAAM,CAACC,cAAc,EAAEC,WAAW,CAAC,GAAG,KAAK,CAACH,sCAAsC,CAACC,OAAO,CAAC;IAC3F,IAAIE,WAAW,aAAXA,WAAW,eAAXA,WAAW,CAAEC,OAAO,IAAI,CAACD,WAAW,CAACE,MAAM,EAAE;MAC7CF,WAAW,CAACE,MAAM,GAAGC,WAAW,CAACF,OAAO,CAACD,WAAW,CAACC,OAAO,CAAC;IACjE;IACA,OAAO,CAACF,cAAc,EAAEC,WAAW,CAAC;EACxC;EACA,MAAMI,MAAMA,CAACC,KAAK,EAAEP,OAAO,EAAE;IACzB,MAAMQ,WAAW,GAAGnB,aAAa,CAACoB,0BAA0B,CAACF,KAAK,CAAC;IACnE,MAAMG,MAAM,GAAG,MAAM,IAAI,CAACC,cAAc,CAAC,CAACH,WAAW,CAAC,EAAER,OAAO,EAAEA,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEY,SAAS,CAAC;IACpF,MAAMC,cAAc,GAAGH,MAAM,CAACI,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/C;IACA,OAAOD,cAAc,CAACE,OAAO;EACjC;EACA;EACA,OAAOC,qBAAqBA,CAACC,SAAS,EAAEC,QAAQ,EAAEC,WAAW,EAAE;IAC3D,MAAM,IAAIC,KAAK,CAAC,kBAAkB,CAAC;EACvC;EACA,OAAOC,eAAeA,CAACd,KAAK,EAAEP,OAAO,EAAE;IACnC;IACA,IAAI,IAAI,CAACgB,qBAAqB,KAC1B3B,aAAa,CAACiC,SAAS,CAACN,qBAAqB,EAAE;MAC/C,MAAM,IAAI,CAACV,MAAM,CAACC,KAAK,EAAEP,OAAO,CAAC;IACrC,CAAC,MACI;MACD,MAAMuB,MAAM,GAAGlC,aAAa,CAACoB,0BAA0B,CAACF,KAAK,CAAC;MAC9D,MAAMiB,QAAQ,GAAGD,MAAM,CAACE,cAAc,CAAC,CAAC;MACxC,MAAM,CAACxB,cAAc,EAAEC,WAAW,CAAC,GAAG,IAAI,CAACH,sCAAsC,CAACC,OAAO,CAAC;MAC1F,MAAM0B,gBAAgB,GAAG,MAAMhD,eAAe,CAACiD,SAAS,CAAC1B,cAAc,CAACW,SAAS,EAAE,IAAI,CAACA,SAAS,EAAEX,cAAc,CAAC2B,IAAI,EAAE,IAAI,CAACA,IAAI,EAAE3B,cAAc,CAAC4B,QAAQ,EAAE,IAAI,CAACA,QAAQ,EAAE;QAAEC,OAAO,EAAE,IAAI,CAACA;MAAQ,CAAC,CAAC;MACrM,MAAMC,KAAK,GAAG;QACV/B,OAAO,EAAEE,WAAW;QACpB8B,iBAAiB,EAAE,IAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAEC,gBAAgB,CAAC/B,WAAW;MACzD,CAAC;MACD,MAAMgC,WAAW,GAAG,OAAMR,gBAAgB,aAAhBA,gBAAgB,uBAAhBA,gBAAgB,CAAES,oBAAoB,CAAC,IAAI,CAACC,MAAM,CAAC,CAAC,EAAE,CAACZ,QAAQ,CAAC,EAAEa,SAAS,EAAEA,SAAS,EAAEN,KAAK,CAAC;MACxH,IAAIO,eAAe;MACnB,IAAI;QACA,WAAW,MAAMtD,KAAK,IAAI,IAAI,CAACgC,qBAAqB,CAACQ,QAAQ,EAAEtB,WAAW,EAAEgC,WAAW,aAAXA,WAAW,uBAAXA,WAAW,CAAG,CAAC,CAAC,CAAC,EAAE;UAC3F,MAAMlD,KAAK,CAAC+B,OAAO;UACnB,IAAI,CAACuB,eAAe,EAAE;YAClBA,eAAe,GAAGtD,KAAK;UAC3B,CAAC,MACI;YACDsD,eAAe,GAAGA,eAAe,CAACC,MAAM,CAACvD,KAAK,CAAC;UACnD;QACJ;MACJ,CAAC,CACD,OAAOwD,GAAG,EAAE;QACR,MAAMC,OAAO,CAACC,GAAG,CAAC,CAACR,WAAW,aAAXA,WAAW,cAAXA,WAAW,GAAI,EAAE,EAAES,GAAG,CAAEC,UAAU,IAAKA,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEC,cAAc,CAACL,GAAG,CAAC,CAAC,CAAC;QAC3F,MAAMA,GAAG;MACb;MACA,MAAMC,OAAO,CAACC,GAAG,CAAC,CAACR,WAAW,aAAXA,WAAW,cAAXA,WAAW,GAAI,EAAE,EAAES,GAAG,CAAEC,UAAU,IAAKA,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEE,YAAY,CAAC;QAC/E;QACAhC,WAAW,EAAE,CAAC,CAACwB,eAAe,CAAC;MACnC,CAAC,CAAC,CAAC,CAAC;IACR;EACJ;EACA,MAAMS,QAAQA,CAACvB,QAAQ,EAAExB,OAAO,EAAEY,SAAS,EAAE;IAAA,IAAAoC,qBAAA,EAAAC,qBAAA;IACzC;IACA,IAAIC,aAAa;IACjB,IAAIC,KAAK,CAACC,OAAO,CAACpD,OAAO,CAAC,EAAE;MACxBkD,aAAa,GAAG;QAAEG,IAAI,EAAErD;MAAQ,CAAC;IACrC,CAAC,MACI;MACDkD,aAAa,GAAGlD,OAAO;IAC3B;IACA,MAAM,CAACC,cAAc,EAAEC,WAAW,CAAC,GAAG,IAAI,CAACH,sCAAsC,CAACmD,aAAa,CAAC;IAChG;IACA,MAAMxB,gBAAgB,GAAG,MAAMhD,eAAe,CAACiD,SAAS,EAAAqB,qBAAA,GAAC/C,cAAc,CAACW,SAAS,cAAAoC,qBAAA,cAAAA,qBAAA,GAAIpC,SAAS,EAAE,IAAI,CAACA,SAAS,EAAEX,cAAc,CAAC2B,IAAI,EAAE,IAAI,CAACA,IAAI,EAAE3B,cAAc,CAAC4B,QAAQ,EAAE,IAAI,CAACA,QAAQ,EAAE;MAAEC,OAAO,EAAE,IAAI,CAACA;IAAQ,CAAC,CAAC;IAClN,MAAMC,KAAK,GAAG;MACV/B,OAAO,EAAEE,WAAW;MACpB8B,iBAAiB,EAAE,IAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAEC,gBAAgB,CAACiB,aAAa;IAC3D,CAAC;IACD,MAAMhB,WAAW,GAAG,OAAMR,gBAAgB,aAAhBA,gBAAgB,uBAAhBA,gBAAgB,CAAES,oBAAoB,CAAC,IAAI,CAACC,MAAM,CAAC,CAAC,EAAEZ,QAAQ,EAAEa,SAAS,EAAEA,SAAS,EAAEN,KAAK,CAAC;IACtH;IACA,MAAMuB,OAAO,GAAG,MAAMb,OAAO,CAACc,UAAU,CAAC/B,QAAQ,CAACmB,GAAG,CAAC,CAACa,WAAW,EAAEC,CAAC,KAAK,IAAI,CAACC,SAAS,CAACF,WAAW,EAAE;MAAE,GAAGtD,WAAW;MAAEyD,WAAW,EAAEF;IAAE,CAAC,EAAEvB,WAAW,aAAXA,WAAW,uBAAXA,WAAW,CAAGuB,CAAC,CAAC,CAAC,CAAC,CAAC;IAC7J;IACA,MAAM3C,WAAW,GAAG,EAAE;IACtB,MAAM8C,UAAU,GAAG,EAAE;IACrB,MAAMnB,OAAO,CAACC,GAAG,CAACY,OAAO,CAACX,GAAG,CAAC,OAAOkB,OAAO,EAAEJ,CAAC,KAAK;MAChD,IAAII,OAAO,CAACC,MAAM,KAAK,WAAW,EAAE;QAAA,IAAAC,cAAA;QAChC,MAAMrD,MAAM,GAAGmD,OAAO,CAAChE,KAAK;QAC5BiB,WAAW,CAAC2C,CAAC,CAAC,GAAG/C,MAAM,CAACI,WAAW;QACnC8C,UAAU,CAACH,CAAC,CAAC,GAAG/C,MAAM,CAACsD,SAAS;QAChC,OAAO9B,WAAW,aAAXA,WAAW,gBAAA6B,cAAA,GAAX7B,WAAW,CAAGuB,CAAC,CAAC,cAAAM,cAAA,uBAAhBA,cAAA,CAAkBjB,YAAY,CAAC;UAClChC,WAAW,EAAE,CAACJ,MAAM,CAACI,WAAW,CAAC;UACjCkD,SAAS,EAAEtD,MAAM,CAACsD;QACtB,CAAC,CAAC;MACN,CAAC,MACI;QAAA,IAAAC,eAAA;QACD;QACA,OAAM/B,WAAW,aAAXA,WAAW,gBAAA+B,eAAA,GAAX/B,WAAW,CAAGuB,CAAC,CAAC,cAAAQ,eAAA,uBAAhBA,eAAA,CAAkBpB,cAAc,CAACgB,OAAO,CAACK,MAAM,CAAC;QACtD,OAAOzB,OAAO,CAAC0B,MAAM,CAACN,OAAO,CAACK,MAAM,CAAC;MACzC;IACJ,CAAC,CAAC,CAAC;IACH;IACA,MAAME,MAAM,GAAG;MACXtD,WAAW;MACXkD,SAAS,EAAEJ,UAAU,CAACS,MAAM,IAAApB,qBAAA,GACtB,IAAI,CAACqB,iBAAiB,cAAArB,qBAAA,uBAAtBA,qBAAA,CAAAsB,IAAA,KAAI,EAAqB,GAAGX,UAAU,CAAC,GACvCvB;IACV,CAAC;IACD7C,MAAM,CAACC,cAAc,CAAC2E,MAAM,EAAE5F,OAAO,EAAE;MACnCqB,KAAK,EAAEqC,WAAW,GACZ;QAAEsC,MAAM,EAAEtC,WAAW,aAAXA,WAAW,uBAAXA,WAAW,CAAES,GAAG,CAAE8B,OAAO,IAAKA,OAAO,CAACC,KAAK;MAAE,CAAC,GACxDrC,SAAS;MACf1C,YAAY,EAAE;IAClB,CAAC,CAAC;IACF,OAAOyE,MAAM;EACjB;EACA;AACJ;AACA;EACI;EACAnC,gBAAgBA,CAACf,QAAQ,EAAE;IACvB,OAAO,CAAC,CAAC;EACb;EACAyD,UAAUA,CAAA,EAAG;IACT,OAAO,iBAAiB;EAC5B;EACA,MAAMhE,cAAcA,CAACiE,YAAY,EAAE5E,OAAO,EAAEY,SAAS,EAAE;IACnD,MAAMiE,cAAc,GAAGD,YAAY,CAACjC,GAAG,CAAEnC,WAAW,IAAKA,WAAW,CAACiB,cAAc,CAAC,CAAC,CAAC;IACtF,OAAO,IAAI,CAACsB,QAAQ,CAAC8B,cAAc,EAAE7E,OAAO,EAAEY,SAAS,CAAC;EAC5D;EACA,MAAM2D,IAAIA,CAAC/C,QAAQ,EAAExB,OAAO,EAAEY,SAAS,EAAE;IACrC,MAAMF,MAAM,GAAG,MAAM,IAAI,CAACqC,QAAQ,CAAC,CAACvB,QAAQ,CAAC,EAAExB,OAAO,EAAEY,SAAS,CAAC;IAClE,MAAME,WAAW,GAAGJ,MAAM,CAACI,WAAW;IACtC,OAAOA,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACC,OAAO;EACpC;EACA,MAAM+D,UAAUA,CAACtE,WAAW,EAAER,OAAO,EAAEY,SAAS,EAAE;IAC9C,MAAMiE,cAAc,GAAGrE,WAAW,CAACiB,cAAc,CAAC,CAAC;IACnD,OAAO,IAAI,CAAC8C,IAAI,CAACM,cAAc,EAAE7E,OAAO,EAAEY,SAAS,CAAC;EACxD;EACA,MAAMmE,eAAeA,CAACvD,QAAQ,EAAExB,OAAO,EAAEY,SAAS,EAAE;IAChD,OAAO,IAAI,CAAC2D,IAAI,CAAC/C,QAAQ,EAAExB,OAAO,EAAEY,SAAS,CAAC;EAClD;EACA,MAAMoE,OAAOA,CAACC,IAAI,EAAEjF,OAAO,EAAEY,SAAS,EAAE;IACpC,MAAMG,OAAO,GAAG,IAAIxC,YAAY,CAAC0G,IAAI,CAAC;IACtC,MAAMvE,MAAM,GAAG,MAAM,IAAI,CAAC6D,IAAI,CAAC,CAACxD,OAAO,CAAC,EAAEf,OAAO,EAAEY,SAAS,CAAC;IAC7D,OAAOF,MAAM,CAACtB,OAAO;EACzB;AACJ;AACA,OAAO,MAAM8F,eAAe,SAAS7F,aAAa,CAAC;EAC/C,MAAMqE,SAASA,CAAClC,QAAQ,EAAExB,OAAO,EAAE4C,UAAU,EAAE;IAC3C,MAAMqC,IAAI,GAAG,MAAM,IAAI,CAACE,KAAK,CAAC3D,QAAQ,EAAExB,OAAO,EAAE4C,UAAU,CAAC;IAC5D,MAAM7B,OAAO,GAAG,IAAIzC,SAAS,CAAC2G,IAAI,CAAC;IACnC,OAAO;MACHnE,WAAW,EAAE,CACT;QACImE,IAAI,EAAElE,OAAO,CAAC3B,OAAO;QACrB2B;MACJ,CAAC;IAET,CAAC;EACL;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}