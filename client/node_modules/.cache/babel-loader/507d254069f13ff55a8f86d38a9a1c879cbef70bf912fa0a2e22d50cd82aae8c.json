{"ast":null,"code":"import { Configuration, OpenAIApi } from \"openai\";\nimport { getModelNameForTiktoken } from \"../base_language/count_tokens.js\";\nimport { AIMessage, AIMessageChunk, ChatGenerationChunk, ChatMessage, ChatMessageChunk, FunctionMessageChunk, HumanMessage, HumanMessageChunk, SystemMessage, SystemMessageChunk } from \"../schema/index.js\";\nimport { formatToOpenAIFunction } from \"../tools/convert_to_openai.js\";\nimport fetchAdapter from \"../util/axios-fetch-adapter.js\";\nimport { getEndpoint } from \"../util/azure.js\";\nimport { getEnvironmentVariable, isNode } from \"../util/env.js\";\nimport { promptLayerTrackRequest } from \"../util/prompt-layer.js\";\nimport { readableStreamToAsyncIterable } from \"../util/stream.js\";\nimport { BaseChatModel } from \"./base.js\";\nfunction extractGenericMessageCustomRole(message) {\n  if (message.role !== \"system\" && message.role !== \"assistant\" && message.role !== \"user\" && message.role !== \"function\") {\n    console.warn(\"Unknown message role: \".concat(message.role));\n  }\n  return message.role;\n}\nfunction messageToOpenAIRole(message) {\n  const type = message._getType();\n  switch (type) {\n    case \"system\":\n      return \"system\";\n    case \"ai\":\n      return \"assistant\";\n    case \"human\":\n      return \"user\";\n    case \"function\":\n      return \"function\";\n    case \"generic\":\n      {\n        if (!ChatMessage.isInstance(message)) throw new Error(\"Invalid generic chat message\");\n        return extractGenericMessageCustomRole(message);\n      }\n    default:\n      throw new Error(\"Unknown message type: \".concat(type));\n  }\n}\nfunction openAIResponseToChatMessage(message) {\n  var _message$role;\n  switch (message.role) {\n    case \"user\":\n      return new HumanMessage(message.content || \"\");\n    case \"assistant\":\n      return new AIMessage(message.content || \"\", {\n        function_call: message.function_call\n      });\n    case \"system\":\n      return new SystemMessage(message.content || \"\");\n    default:\n      return new ChatMessage(message.content || \"\", (_message$role = message.role) !== null && _message$role !== void 0 ? _message$role : \"unknown\");\n  }\n}\nfunction _convertDeltaToMessageChunk(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ndelta, defaultRole) {\n  var _delta$role, _delta$content;\n  const role = (_delta$role = delta.role) !== null && _delta$role !== void 0 ? _delta$role : defaultRole;\n  const content = (_delta$content = delta.content) !== null && _delta$content !== void 0 ? _delta$content : \"\";\n  let additional_kwargs;\n  if (delta.function_call) {\n    additional_kwargs = {\n      function_call: delta.function_call\n    };\n  } else {\n    additional_kwargs = {};\n  }\n  if (role === \"user\") {\n    return new HumanMessageChunk({\n      content\n    });\n  } else if (role === \"assistant\") {\n    return new AIMessageChunk({\n      content,\n      additional_kwargs\n    });\n  } else if (role === \"system\") {\n    return new SystemMessageChunk({\n      content\n    });\n  } else if (role === \"function\") {\n    return new FunctionMessageChunk({\n      content,\n      additional_kwargs,\n      name: delta.name\n    });\n  } else {\n    return new ChatMessageChunk({\n      content,\n      role\n    });\n  }\n}\n/**\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n * `AZURE_OPENAI_BASE_PATH` is optional and will override `AZURE_OPENAI_API_INSTANCE_NAME` if you need to use a custom endpoint.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createChatCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n */\nexport class ChatOpenAI extends BaseChatModel {\n  static lc_name() {\n    return \"ChatOpenAI\";\n  }\n  get callKeys() {\n    return [...super.callKeys, \"options\", \"function_call\", \"functions\", \"tools\", \"promptIndex\"];\n  }\n  get lc_secrets() {\n    return {\n      openAIApiKey: \"OPENAI_API_KEY\",\n      azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n      organization: \"OPENAI_ORGANIZATION\"\n    };\n  }\n  get lc_aliases() {\n    return {\n      modelName: \"model\",\n      openAIApiKey: \"openai_api_key\",\n      azureOpenAIApiVersion: \"azure_openai_api_version\",\n      azureOpenAIApiKey: \"azure_openai_api_key\",\n      azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n      azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\"\n    };\n  }\n  constructor(fields, /** @deprecated */\n  configuration) {\n    var _fields$openAIApiKey, _fields$azureOpenAIAp, _fields$azureOpenAIAp2, _fields$azureOpenAIAp3, _fields$azureOpenAIAp4, _fields$azureOpenAIBa, _fields$configuration, _fields$configuration2, _fields$modelName, _fields$modelKwargs, _fields$temperature, _fields$topP, _fields$frequencyPena, _fields$presencePenal, _fields$n, _fields$streaming;\n    super(fields !== null && fields !== void 0 ? fields : {});\n    Object.defineProperty(this, \"lc_serializable\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: true\n    });\n    Object.defineProperty(this, \"temperature\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"topP\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"frequencyPenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"presencePenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"n\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"logitBias\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"modelName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"gpt-3.5-turbo\"\n    });\n    Object.defineProperty(this, \"modelKwargs\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"stop\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"user\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"timeout\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"streaming\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: false\n    });\n    Object.defineProperty(this, \"maxTokens\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"openAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIBasePath\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"organization\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"client\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"clientConfig\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.openAIApiKey = (_fields$openAIApiKey = fields === null || fields === void 0 ? void 0 : fields.openAIApiKey) !== null && _fields$openAIApiKey !== void 0 ? _fields$openAIApiKey : getEnvironmentVariable(\"OPENAI_API_KEY\");\n    this.azureOpenAIApiKey = (_fields$azureOpenAIAp = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiKey) !== null && _fields$azureOpenAIAp !== void 0 ? _fields$azureOpenAIAp : getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n    if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n      throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n    }\n    this.azureOpenAIApiInstanceName = (_fields$azureOpenAIAp2 = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiInstanceName) !== null && _fields$azureOpenAIAp2 !== void 0 ? _fields$azureOpenAIAp2 : getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n    this.azureOpenAIApiDeploymentName = (_fields$azureOpenAIAp3 = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiDeploymentName) !== null && _fields$azureOpenAIAp3 !== void 0 ? _fields$azureOpenAIAp3 : getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\");\n    this.azureOpenAIApiVersion = (_fields$azureOpenAIAp4 = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiVersion) !== null && _fields$azureOpenAIAp4 !== void 0 ? _fields$azureOpenAIAp4 : getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n    this.azureOpenAIBasePath = (_fields$azureOpenAIBa = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIBasePath) !== null && _fields$azureOpenAIBa !== void 0 ? _fields$azureOpenAIBa : getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n    this.organization = (_fields$configuration = fields === null || fields === void 0 || (_fields$configuration2 = fields.configuration) === null || _fields$configuration2 === void 0 ? void 0 : _fields$configuration2.organization) !== null && _fields$configuration !== void 0 ? _fields$configuration : getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n    this.modelName = (_fields$modelName = fields === null || fields === void 0 ? void 0 : fields.modelName) !== null && _fields$modelName !== void 0 ? _fields$modelName : this.modelName;\n    this.modelKwargs = (_fields$modelKwargs = fields === null || fields === void 0 ? void 0 : fields.modelKwargs) !== null && _fields$modelKwargs !== void 0 ? _fields$modelKwargs : {};\n    this.timeout = fields === null || fields === void 0 ? void 0 : fields.timeout;\n    this.temperature = (_fields$temperature = fields === null || fields === void 0 ? void 0 : fields.temperature) !== null && _fields$temperature !== void 0 ? _fields$temperature : this.temperature;\n    this.topP = (_fields$topP = fields === null || fields === void 0 ? void 0 : fields.topP) !== null && _fields$topP !== void 0 ? _fields$topP : this.topP;\n    this.frequencyPenalty = (_fields$frequencyPena = fields === null || fields === void 0 ? void 0 : fields.frequencyPenalty) !== null && _fields$frequencyPena !== void 0 ? _fields$frequencyPena : this.frequencyPenalty;\n    this.presencePenalty = (_fields$presencePenal = fields === null || fields === void 0 ? void 0 : fields.presencePenalty) !== null && _fields$presencePenal !== void 0 ? _fields$presencePenal : this.presencePenalty;\n    this.maxTokens = fields === null || fields === void 0 ? void 0 : fields.maxTokens;\n    this.n = (_fields$n = fields === null || fields === void 0 ? void 0 : fields.n) !== null && _fields$n !== void 0 ? _fields$n : this.n;\n    this.logitBias = fields === null || fields === void 0 ? void 0 : fields.logitBias;\n    this.stop = fields === null || fields === void 0 ? void 0 : fields.stop;\n    this.user = fields === null || fields === void 0 ? void 0 : fields.user;\n    this.streaming = (_fields$streaming = fields === null || fields === void 0 ? void 0 : fields.streaming) !== null && _fields$streaming !== void 0 ? _fields$streaming : false;\n    if (this.azureOpenAIApiKey) {\n      if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n        throw new Error(\"Azure OpenAI API instance name not found\");\n      }\n      if (!this.azureOpenAIApiDeploymentName) {\n        throw new Error(\"Azure OpenAI API deployment name not found\");\n      }\n      if (!this.azureOpenAIApiVersion) {\n        throw new Error(\"Azure OpenAI API version not found\");\n      }\n    }\n    this.clientConfig = {\n      apiKey: this.openAIApiKey,\n      organization: this.organization,\n      ...configuration,\n      ...(fields === null || fields === void 0 ? void 0 : fields.configuration)\n    };\n  }\n  /**\n   * Get the parameters used to invoke the model\n   */\n  invocationParams(options) {\n    var _options$stop, _options$functions;\n    return {\n      model: this.modelName,\n      temperature: this.temperature,\n      top_p: this.topP,\n      frequency_penalty: this.frequencyPenalty,\n      presence_penalty: this.presencePenalty,\n      max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n      n: this.n,\n      logit_bias: this.logitBias,\n      stop: (_options$stop = options === null || options === void 0 ? void 0 : options.stop) !== null && _options$stop !== void 0 ? _options$stop : this.stop,\n      user: this.user,\n      stream: this.streaming,\n      functions: (_options$functions = options === null || options === void 0 ? void 0 : options.functions) !== null && _options$functions !== void 0 ? _options$functions : options !== null && options !== void 0 && options.tools ? options === null || options === void 0 ? void 0 : options.tools.map(formatToOpenAIFunction) : undefined,\n      function_call: options === null || options === void 0 ? void 0 : options.function_call,\n      ...this.modelKwargs\n    };\n  }\n  /** @ignore */\n  _identifyingParams() {\n    return {\n      model_name: this.modelName,\n      ...this.invocationParams(),\n      ...this.clientConfig\n    };\n  }\n  // TODO(jacoblee): Refactor with _generate(..., {stream: true}) implementation\n  // when we integrate OpenAI's new SDK.\n  async *_streamResponseChunks(messages, options, runManager) {\n    const messagesMapped = messages.map(message => ({\n      role: messageToOpenAIRole(message),\n      content: message.content,\n      name: message.name,\n      function_call: message.additional_kwargs.function_call\n    }));\n    const params = {\n      ...this.invocationParams(options),\n      messages: messagesMapped,\n      stream: true\n    };\n    let defaultRole = \"assistant\";\n    const streamIterable = this.startStream(params, options);\n    for await (const streamedResponse of streamIterable) {\n      var _data$choices, _delta$role2, _generationChunk$text;\n      const data = JSON.parse(streamedResponse);\n      const choice = (_data$choices = data.choices) === null || _data$choices === void 0 ? void 0 : _data$choices[0];\n      if (!choice) {\n        continue;\n      }\n      const {\n        delta\n      } = choice;\n      const chunk = _convertDeltaToMessageChunk(delta, defaultRole);\n      defaultRole = (_delta$role2 = delta.role) !== null && _delta$role2 !== void 0 ? _delta$role2 : defaultRole;\n      const generationChunk = new ChatGenerationChunk({\n        message: chunk,\n        text: chunk.content\n      });\n      yield generationChunk;\n      // eslint-disable-next-line no-void\n      void (runManager === null || runManager === void 0 ? void 0 : runManager.handleLLMNewToken((_generationChunk$text = generationChunk.text) !== null && _generationChunk$text !== void 0 ? _generationChunk$text : \"\"));\n    }\n  }\n  startStream(request, options) {\n    let done = false;\n    const stream = new TransformStream();\n    const writer = stream.writable.getWriter();\n    const iterable = readableStreamToAsyncIterable(stream.readable);\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    let err;\n    this.completionWithRetry(request, {\n      ...options,\n      adapter: fetchAdapter,\n      responseType: \"stream\",\n      onmessage: event => {\n        var _event$data, _event$data$trim;\n        if (done) return;\n        if (((_event$data = event.data) === null || _event$data === void 0 || (_event$data$trim = _event$data.trim) === null || _event$data$trim === void 0 ? void 0 : _event$data$trim.call(_event$data)) === \"[DONE]\") {\n          done = true;\n          // eslint-disable-next-line no-void\n          void writer.close();\n        } else {\n          const data = JSON.parse(event.data);\n          if (data.error) {\n            done = true;\n            throw data.error;\n          }\n          // eslint-disable-next-line no-void\n          void writer.write(event.data);\n        }\n      }\n    }).catch(error => {\n      if (!done) {\n        err = error;\n        done = true;\n        // eslint-disable-next-line no-void\n        void writer.close();\n      }\n    });\n    return {\n      async next() {\n        const chunk = await iterable.next();\n        if (err) {\n          throw err;\n        }\n        return chunk;\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      }\n    };\n  }\n  /**\n   * Get the identifying parameters for the model\n   */\n  identifyingParams() {\n    return this._identifyingParams();\n  }\n  /** @ignore */\n  async _generate(messages, options, runManager) {\n    var _data$usage;\n    const tokenUsage = {};\n    const params = this.invocationParams(options);\n    const messagesMapped = messages.map(message => ({\n      role: messageToOpenAIRole(message),\n      content: message.content,\n      name: message.name,\n      function_call: message.additional_kwargs.function_call\n    }));\n    const data = params.stream ? await new Promise((resolve, reject) => {\n      let response;\n      let rejected = false;\n      let resolved = false;\n      this.completionWithRetry({\n        ...params,\n        messages: messagesMapped\n      }, {\n        signal: options === null || options === void 0 ? void 0 : options.signal,\n        ...(options === null || options === void 0 ? void 0 : options.options),\n        adapter: fetchAdapter,\n        responseType: \"stream\",\n        onmessage: event => {\n          var _event$data2, _event$data2$trim;\n          if (((_event$data2 = event.data) === null || _event$data2 === void 0 || (_event$data2$trim = _event$data2.trim) === null || _event$data2$trim === void 0 ? void 0 : _event$data2$trim.call(_event$data2)) === \"[DONE]\") {\n            if (resolved || rejected) {\n              return;\n            }\n            resolved = true;\n            resolve(response);\n          } else {\n            var _message$choices2;\n            const data = JSON.parse(event.data);\n            if (!data.id) return;\n            if (data !== null && data !== void 0 && data.error) {\n              if (rejected) {\n                return;\n              }\n              rejected = true;\n              reject(data.error);\n              return;\n            }\n            const message = data;\n            // on the first message set the response properties\n            if (!response) {\n              response = {\n                id: message.id,\n                object: message.object,\n                created: message.created,\n                model: message.model,\n                choices: []\n              };\n            }\n            // on all messages, update choice\n            for (const part of (_message$choices = message.choices) !== null && _message$choices !== void 0 ? _message$choices : []) {\n              var _message$choices;\n              if (part != null) {\n                var _part$delta$content, _part$delta2, _part$delta$content2, _part$delta5, _options$promptIndex;\n                let choice = response.choices.find(c => c.index === part.index);\n                if (!choice) {\n                  var _part$finish_reason;\n                  choice = {\n                    index: part.index,\n                    finish_reason: (_part$finish_reason = part.finish_reason) !== null && _part$finish_reason !== void 0 ? _part$finish_reason : undefined\n                  };\n                  response.choices[part.index] = choice;\n                }\n                if (!choice.message) {\n                  var _part$delta;\n                  choice.message = {\n                    role: (_part$delta = part.delta) === null || _part$delta === void 0 ? void 0 : _part$delta.role,\n                    content: \"\"\n                  };\n                }\n                if (part.delta.function_call && !choice.message.function_call) {\n                  choice.message.function_call = {\n                    name: \"\",\n                    arguments: \"\"\n                  };\n                }\n                choice.message.content += (_part$delta$content = (_part$delta2 = part.delta) === null || _part$delta2 === void 0 ? void 0 : _part$delta2.content) !== null && _part$delta$content !== void 0 ? _part$delta$content : \"\";\n                if (choice.message.function_call) {\n                  var _part$delta$function_, _part$delta3, _part$delta$function_2, _part$delta4;\n                  choice.message.function_call.name += (_part$delta$function_ = (_part$delta3 = part.delta) === null || _part$delta3 === void 0 || (_part$delta3 = _part$delta3.function_call) === null || _part$delta3 === void 0 ? void 0 : _part$delta3.name) !== null && _part$delta$function_ !== void 0 ? _part$delta$function_ : \"\";\n                  choice.message.function_call.arguments += (_part$delta$function_2 = (_part$delta4 = part.delta) === null || _part$delta4 === void 0 || (_part$delta4 = _part$delta4.function_call) === null || _part$delta4 === void 0 ? void 0 : _part$delta4.arguments) !== null && _part$delta$function_2 !== void 0 ? _part$delta$function_2 : \"\";\n                }\n                // eslint-disable-next-line no-void\n                void (runManager === null || runManager === void 0 ? void 0 : runManager.handleLLMNewToken((_part$delta$content2 = (_part$delta5 = part.delta) === null || _part$delta5 === void 0 ? void 0 : _part$delta5.content) !== null && _part$delta$content2 !== void 0 ? _part$delta$content2 : \"\", {\n                  prompt: (_options$promptIndex = options.promptIndex) !== null && _options$promptIndex !== void 0 ? _options$promptIndex : 0,\n                  completion: part.index\n                }));\n                // TODO we don't currently have a callback method for\n                // sending the function call arguments\n              }\n            }\n            // when all messages are finished, resolve\n            if (!resolved && !rejected && (_message$choices2 = message.choices) !== null && _message$choices2 !== void 0 && _message$choices2.every(c => c.finish_reason != null)) {\n              resolved = true;\n              resolve(response);\n            }\n          }\n        }\n      }).catch(error => {\n        if (!rejected) {\n          rejected = true;\n          reject(error);\n        }\n      });\n    }) : await this.completionWithRetry({\n      ...params,\n      messages: messagesMapped\n    }, {\n      signal: options === null || options === void 0 ? void 0 : options.signal,\n      ...(options === null || options === void 0 ? void 0 : options.options)\n    });\n    const {\n      completion_tokens: completionTokens,\n      prompt_tokens: promptTokens,\n      total_tokens: totalTokens\n    } = (_data$usage = data.usage) !== null && _data$usage !== void 0 ? _data$usage : {};\n    if (completionTokens) {\n      var _tokenUsage$completio;\n      tokenUsage.completionTokens = ((_tokenUsage$completio = tokenUsage.completionTokens) !== null && _tokenUsage$completio !== void 0 ? _tokenUsage$completio : 0) + completionTokens;\n    }\n    if (promptTokens) {\n      var _tokenUsage$promptTok;\n      tokenUsage.promptTokens = ((_tokenUsage$promptTok = tokenUsage.promptTokens) !== null && _tokenUsage$promptTok !== void 0 ? _tokenUsage$promptTok : 0) + promptTokens;\n    }\n    if (totalTokens) {\n      var _tokenUsage$totalToke;\n      tokenUsage.totalTokens = ((_tokenUsage$totalToke = tokenUsage.totalTokens) !== null && _tokenUsage$totalToke !== void 0 ? _tokenUsage$totalToke : 0) + totalTokens;\n    }\n    const generations = [];\n    for (const part of data.choices) {\n      var _part$message$content, _part$message, _part$message2;\n      const text = (_part$message$content = (_part$message = part.message) === null || _part$message === void 0 ? void 0 : _part$message.content) !== null && _part$message$content !== void 0 ? _part$message$content : \"\";\n      generations.push({\n        text,\n        message: openAIResponseToChatMessage((_part$message2 = part.message) !== null && _part$message2 !== void 0 ? _part$message2 : {\n          role: \"assistant\"\n        })\n      });\n    }\n    return {\n      generations,\n      llmOutput: {\n        tokenUsage\n      }\n    };\n  }\n  async getNumTokensFromMessages(messages) {\n    let totalCount = 0;\n    let tokensPerMessage = 0;\n    let tokensPerName = 0;\n    // From: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n    if (getModelNameForTiktoken(this.modelName) === \"gpt-3.5-turbo\") {\n      tokensPerMessage = 4;\n      tokensPerName = -1;\n    } else if (getModelNameForTiktoken(this.modelName).startsWith(\"gpt-4\")) {\n      tokensPerMessage = 3;\n      tokensPerName = 1;\n    }\n    const countPerMessage = await Promise.all(messages.map(async message => {\n      const textCount = await this.getNumTokens(message.content);\n      const roleCount = await this.getNumTokens(messageToOpenAIRole(message));\n      const nameCount = message.name !== undefined ? tokensPerName + (await this.getNumTokens(message.name)) : 0;\n      const count = textCount + tokensPerMessage + roleCount + nameCount;\n      totalCount += count;\n      return count;\n    }));\n    totalCount += 3; // every reply is primed with <|start|>assistant<|message|>\n    return {\n      totalCount,\n      countPerMessage\n    };\n  }\n  /** @ignore */\n  async completionWithRetry(request, options) {\n    if (!this.client) {\n      const openAIEndpointConfig = {\n        azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n        azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n        azureOpenAIApiKey: this.azureOpenAIApiKey,\n        azureOpenAIBasePath: this.azureOpenAIBasePath,\n        basePath: this.clientConfig.basePath\n      };\n      const endpoint = getEndpoint(openAIEndpointConfig);\n      const clientConfig = new Configuration({\n        ...this.clientConfig,\n        basePath: endpoint,\n        baseOptions: {\n          timeout: this.timeout,\n          ...this.clientConfig.baseOptions\n        }\n      });\n      this.client = new OpenAIApi(clientConfig);\n    }\n    const axiosOptions = {\n      adapter: isNode() ? undefined : fetchAdapter,\n      ...this.clientConfig.baseOptions,\n      ...options\n    };\n    if (this.azureOpenAIApiKey) {\n      axiosOptions.headers = {\n        \"api-key\": this.azureOpenAIApiKey,\n        ...axiosOptions.headers\n      };\n      axiosOptions.params = {\n        \"api-version\": this.azureOpenAIApiVersion,\n        ...axiosOptions.params\n      };\n    }\n    return this.caller.call(this.client.createChatCompletion.bind(this.client), request, axiosOptions).then(res => res.data);\n  }\n  _llmType() {\n    return \"openai\";\n  }\n  /** @ignore */\n  _combineLLMOutput() {\n    for (var _len = arguments.length, llmOutputs = new Array(_len), _key = 0; _key < _len; _key++) {\n      llmOutputs[_key] = arguments[_key];\n    }\n    return llmOutputs.reduce((acc, llmOutput) => {\n      if (llmOutput && llmOutput.tokenUsage) {\n        var _llmOutput$tokenUsage, _llmOutput$tokenUsage2, _llmOutput$tokenUsage3;\n        acc.tokenUsage.completionTokens += (_llmOutput$tokenUsage = llmOutput.tokenUsage.completionTokens) !== null && _llmOutput$tokenUsage !== void 0 ? _llmOutput$tokenUsage : 0;\n        acc.tokenUsage.promptTokens += (_llmOutput$tokenUsage2 = llmOutput.tokenUsage.promptTokens) !== null && _llmOutput$tokenUsage2 !== void 0 ? _llmOutput$tokenUsage2 : 0;\n        acc.tokenUsage.totalTokens += (_llmOutput$tokenUsage3 = llmOutput.tokenUsage.totalTokens) !== null && _llmOutput$tokenUsage3 !== void 0 ? _llmOutput$tokenUsage3 : 0;\n      }\n      return acc;\n    }, {\n      tokenUsage: {\n        completionTokens: 0,\n        promptTokens: 0,\n        totalTokens: 0\n      }\n    });\n  }\n}\nexport class PromptLayerChatOpenAI extends ChatOpenAI {\n  constructor(fields) {\n    var _fields$promptLayerAp, _process$env, _fields$plTags, _fields$returnPromptL;\n    super(fields);\n    Object.defineProperty(this, \"promptLayerApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"plTags\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"returnPromptLayerId\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.promptLayerApiKey = (_fields$promptLayerAp = fields === null || fields === void 0 ? void 0 : fields.promptLayerApiKey) !== null && _fields$promptLayerAp !== void 0 ? _fields$promptLayerAp : typeof process !== \"undefined\" ? // eslint-disable-next-line no-process-env\n    (_process$env = process.env) === null || _process$env === void 0 ? void 0 : _process$env.PROMPTLAYER_API_KEY : undefined;\n    this.plTags = (_fields$plTags = fields === null || fields === void 0 ? void 0 : fields.plTags) !== null && _fields$plTags !== void 0 ? _fields$plTags : [];\n    this.returnPromptLayerId = (_fields$returnPromptL = fields === null || fields === void 0 ? void 0 : fields.returnPromptLayerId) !== null && _fields$returnPromptL !== void 0 ? _fields$returnPromptL : false;\n  }\n  async _generate(messages, options, runManager) {\n    const requestStartTime = Date.now();\n    let parsedOptions;\n    if (Array.isArray(options)) {\n      parsedOptions = {\n        stop: options\n      };\n    } else if (options !== null && options !== void 0 && options.timeout && !options.signal) {\n      parsedOptions = {\n        ...options,\n        signal: AbortSignal.timeout(options.timeout)\n      };\n    } else {\n      parsedOptions = options !== null && options !== void 0 ? options : {};\n    }\n    const generatedResponses = await super._generate(messages, parsedOptions, runManager);\n    const requestEndTime = Date.now();\n    const _convertMessageToDict = message => {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      let messageDict;\n      if (message._getType() === \"human\") {\n        messageDict = {\n          role: \"user\",\n          content: message.content\n        };\n      } else if (message._getType() === \"ai\") {\n        messageDict = {\n          role: \"assistant\",\n          content: message.content\n        };\n      } else if (message._getType() === \"function\") {\n        messageDict = {\n          role: \"assistant\",\n          content: message.content\n        };\n      } else if (message._getType() === \"system\") {\n        messageDict = {\n          role: \"system\",\n          content: message.content\n        };\n      } else if (message._getType() === \"generic\") {\n        messageDict = {\n          role: message.role,\n          content: message.content\n        };\n      } else {\n        throw new Error(\"Got unknown type \".concat(message));\n      }\n      return messageDict;\n    };\n    const _createMessageDicts = (messages, callOptions) => {\n      const params = {\n        ...this.invocationParams(),\n        model: this.modelName\n      };\n      if (callOptions !== null && callOptions !== void 0 && callOptions.stop) {\n        if (Object.keys(params).includes(\"stop\")) {\n          throw new Error(\"`stop` found in both the input and default params.\");\n        }\n      }\n      const messageDicts = messages.map(message => _convertMessageToDict(message));\n      return messageDicts;\n    };\n    for (let i = 0; i < generatedResponses.generations.length; i += 1) {\n      const generation = generatedResponses.generations[i];\n      const messageDicts = _createMessageDicts(messages, parsedOptions);\n      let promptLayerRequestId;\n      const parsedResp = [{\n        content: generation.text,\n        role: messageToOpenAIRole(generation.message)\n      }];\n      const promptLayerRespBody = await promptLayerTrackRequest(this.caller, \"langchain.PromptLayerChatOpenAI\", messageDicts, this._identifyingParams(), this.plTags, parsedResp, requestStartTime, requestEndTime, this.promptLayerApiKey);\n      if (this.returnPromptLayerId === true) {\n        if (promptLayerRespBody.success === true) {\n          promptLayerRequestId = promptLayerRespBody.request_id;\n        }\n        if (!generation.generationInfo || typeof generation.generationInfo !== \"object\") {\n          generation.generationInfo = {};\n        }\n        generation.generationInfo.promptLayerRequestId = promptLayerRequestId;\n      }\n    }\n    return generatedResponses;\n  }\n}","map":{"version":3,"names":["Configuration","OpenAIApi","getModelNameForTiktoken","AIMessage","AIMessageChunk","ChatGenerationChunk","ChatMessage","ChatMessageChunk","FunctionMessageChunk","HumanMessage","HumanMessageChunk","SystemMessage","SystemMessageChunk","formatToOpenAIFunction","fetchAdapter","getEndpoint","getEnvironmentVariable","isNode","promptLayerTrackRequest","readableStreamToAsyncIterable","BaseChatModel","extractGenericMessageCustomRole","message","role","console","warn","concat","messageToOpenAIRole","type","_getType","isInstance","Error","openAIResponseToChatMessage","_message$role","content","function_call","_convertDeltaToMessageChunk","delta","defaultRole","_delta$role","_delta$content","additional_kwargs","name","ChatOpenAI","lc_name","callKeys","lc_secrets","openAIApiKey","azureOpenAIApiKey","organization","lc_aliases","modelName","azureOpenAIApiVersion","azureOpenAIApiInstanceName","azureOpenAIApiDeploymentName","constructor","fields","configuration","_fields$openAIApiKey","_fields$azureOpenAIAp","_fields$azureOpenAIAp2","_fields$azureOpenAIAp3","_fields$azureOpenAIAp4","_fields$azureOpenAIBa","_fields$configuration","_fields$configuration2","_fields$modelName","_fields$modelKwargs","_fields$temperature","_fields$topP","_fields$frequencyPena","_fields$presencePenal","_fields$n","_fields$streaming","Object","defineProperty","enumerable","configurable","writable","value","azureOpenAIBasePath","modelKwargs","timeout","temperature","topP","frequencyPenalty","presencePenalty","maxTokens","n","logitBias","stop","user","streaming","clientConfig","apiKey","invocationParams","options","_options$stop","_options$functions","model","top_p","frequency_penalty","presence_penalty","max_tokens","undefined","logit_bias","stream","functions","tools","map","_identifyingParams","model_name","_streamResponseChunks","messages","runManager","messagesMapped","params","streamIterable","startStream","streamedResponse","_data$choices","_delta$role2","_generationChunk$text","data","JSON","parse","choice","choices","chunk","generationChunk","text","handleLLMNewToken","request","done","TransformStream","writer","getWriter","iterable","readable","err","completionWithRetry","adapter","responseType","onmessage","event","_event$data","_event$data$trim","trim","call","close","error","write","catch","next","Symbol","asyncIterator","identifyingParams","_generate","_data$usage","tokenUsage","Promise","resolve","reject","response","rejected","resolved","signal","_event$data2","_event$data2$trim","_message$choices2","id","object","created","part","_message$choices","_part$delta$content","_part$delta2","_part$delta$content2","_part$delta5","_options$promptIndex","find","c","index","_part$finish_reason","finish_reason","_part$delta","arguments","_part$delta$function_","_part$delta3","_part$delta$function_2","_part$delta4","prompt","promptIndex","completion","every","completion_tokens","completionTokens","prompt_tokens","promptTokens","total_tokens","totalTokens","usage","_tokenUsage$completio","_tokenUsage$promptTok","_tokenUsage$totalToke","generations","_part$message$content","_part$message","_part$message2","push","llmOutput","getNumTokensFromMessages","totalCount","tokensPerMessage","tokensPerName","startsWith","countPerMessage","all","textCount","getNumTokens","roleCount","nameCount","count","client","openAIEndpointConfig","basePath","endpoint","baseOptions","axiosOptions","headers","caller","createChatCompletion","bind","then","res","_llmType","_combineLLMOutput","_len","length","llmOutputs","Array","_key","reduce","acc","_llmOutput$tokenUsage","_llmOutput$tokenUsage2","_llmOutput$tokenUsage3","PromptLayerChatOpenAI","_fields$promptLayerAp","_process$env","_fields$plTags","_fields$returnPromptL","promptLayerApiKey","process","env","PROMPTLAYER_API_KEY","plTags","returnPromptLayerId","requestStartTime","Date","now","parsedOptions","isArray","AbortSignal","generatedResponses","requestEndTime","_convertMessageToDict","messageDict","_createMessageDicts","callOptions","keys","includes","messageDicts","i","generation","promptLayerRequestId","parsedResp","promptLayerRespBody","success","request_id","generationInfo"],"sources":["C:/Users/zackb/OneDrive/Desktop/Bootcamp/best_project_ever/client/node_modules/langchain/dist/chat_models/openai.js"],"sourcesContent":["import { Configuration, OpenAIApi, } from \"openai\";\nimport { getModelNameForTiktoken } from \"../base_language/count_tokens.js\";\nimport { AIMessage, AIMessageChunk, ChatGenerationChunk, ChatMessage, ChatMessageChunk, FunctionMessageChunk, HumanMessage, HumanMessageChunk, SystemMessage, SystemMessageChunk, } from \"../schema/index.js\";\nimport { formatToOpenAIFunction } from \"../tools/convert_to_openai.js\";\nimport fetchAdapter from \"../util/axios-fetch-adapter.js\";\nimport { getEndpoint } from \"../util/azure.js\";\nimport { getEnvironmentVariable, isNode } from \"../util/env.js\";\nimport { promptLayerTrackRequest } from \"../util/prompt-layer.js\";\nimport { readableStreamToAsyncIterable } from \"../util/stream.js\";\nimport { BaseChatModel } from \"./base.js\";\nfunction extractGenericMessageCustomRole(message) {\n    if (message.role !== \"system\" &&\n        message.role !== \"assistant\" &&\n        message.role !== \"user\" &&\n        message.role !== \"function\") {\n        console.warn(`Unknown message role: ${message.role}`);\n    }\n    return message.role;\n}\nfunction messageToOpenAIRole(message) {\n    const type = message._getType();\n    switch (type) {\n        case \"system\":\n            return \"system\";\n        case \"ai\":\n            return \"assistant\";\n        case \"human\":\n            return \"user\";\n        case \"function\":\n            return \"function\";\n        case \"generic\": {\n            if (!ChatMessage.isInstance(message))\n                throw new Error(\"Invalid generic chat message\");\n            return extractGenericMessageCustomRole(message);\n        }\n        default:\n            throw new Error(`Unknown message type: ${type}`);\n    }\n}\nfunction openAIResponseToChatMessage(message) {\n    switch (message.role) {\n        case \"user\":\n            return new HumanMessage(message.content || \"\");\n        case \"assistant\":\n            return new AIMessage(message.content || \"\", {\n                function_call: message.function_call,\n            });\n        case \"system\":\n            return new SystemMessage(message.content || \"\");\n        default:\n            return new ChatMessage(message.content || \"\", message.role ?? \"unknown\");\n    }\n}\nfunction _convertDeltaToMessageChunk(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ndelta, defaultRole) {\n    const role = delta.role ?? defaultRole;\n    const content = delta.content ?? \"\";\n    let additional_kwargs;\n    if (delta.function_call) {\n        additional_kwargs = {\n            function_call: delta.function_call,\n        };\n    }\n    else {\n        additional_kwargs = {};\n    }\n    if (role === \"user\") {\n        return new HumanMessageChunk({ content });\n    }\n    else if (role === \"assistant\") {\n        return new AIMessageChunk({ content, additional_kwargs });\n    }\n    else if (role === \"system\") {\n        return new SystemMessageChunk({ content });\n    }\n    else if (role === \"function\") {\n        return new FunctionMessageChunk({\n            content,\n            additional_kwargs,\n            name: delta.name,\n        });\n    }\n    else {\n        return new ChatMessageChunk({ content, role });\n    }\n}\n/**\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n * `AZURE_OPENAI_BASE_PATH` is optional and will override `AZURE_OPENAI_API_INSTANCE_NAME` if you need to use a custom endpoint.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createChatCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n */\nexport class ChatOpenAI extends BaseChatModel {\n    static lc_name() {\n        return \"ChatOpenAI\";\n    }\n    get callKeys() {\n        return [\n            ...super.callKeys,\n            \"options\",\n            \"function_call\",\n            \"functions\",\n            \"tools\",\n            \"promptIndex\",\n        ];\n    }\n    get lc_secrets() {\n        return {\n            openAIApiKey: \"OPENAI_API_KEY\",\n            azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n            organization: \"OPENAI_ORGANIZATION\",\n        };\n    }\n    get lc_aliases() {\n        return {\n            modelName: \"model\",\n            openAIApiKey: \"openai_api_key\",\n            azureOpenAIApiVersion: \"azure_openai_api_version\",\n            azureOpenAIApiKey: \"azure_openai_api_key\",\n            azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n            azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\",\n        };\n    }\n    constructor(fields, \n    /** @deprecated */\n    configuration) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"frequencyPenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"presencePenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"n\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"logitBias\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gpt-3.5-turbo\"\n        });\n        Object.defineProperty(this, \"modelKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stop\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"user\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"timeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"openAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIBasePath\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"organization\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"clientConfig\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.openAIApiKey =\n            fields?.openAIApiKey ?? getEnvironmentVariable(\"OPENAI_API_KEY\");\n        this.azureOpenAIApiKey =\n            fields?.azureOpenAIApiKey ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n        if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n            throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n        }\n        this.azureOpenAIApiInstanceName =\n            fields?.azureOpenAIApiInstanceName ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n        this.azureOpenAIApiDeploymentName =\n            fields?.azureOpenAIApiDeploymentName ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\");\n        this.azureOpenAIApiVersion =\n            fields?.azureOpenAIApiVersion ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n        this.azureOpenAIBasePath =\n            fields?.azureOpenAIBasePath ??\n                getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n        this.organization =\n            fields?.configuration?.organization ??\n                getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n        this.modelName = fields?.modelName ?? this.modelName;\n        this.modelKwargs = fields?.modelKwargs ?? {};\n        this.timeout = fields?.timeout;\n        this.temperature = fields?.temperature ?? this.temperature;\n        this.topP = fields?.topP ?? this.topP;\n        this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n        this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n        this.maxTokens = fields?.maxTokens;\n        this.n = fields?.n ?? this.n;\n        this.logitBias = fields?.logitBias;\n        this.stop = fields?.stop;\n        this.user = fields?.user;\n        this.streaming = fields?.streaming ?? false;\n        if (this.azureOpenAIApiKey) {\n            if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n                throw new Error(\"Azure OpenAI API instance name not found\");\n            }\n            if (!this.azureOpenAIApiDeploymentName) {\n                throw new Error(\"Azure OpenAI API deployment name not found\");\n            }\n            if (!this.azureOpenAIApiVersion) {\n                throw new Error(\"Azure OpenAI API version not found\");\n            }\n        }\n        this.clientConfig = {\n            apiKey: this.openAIApiKey,\n            organization: this.organization,\n            ...configuration,\n            ...fields?.configuration,\n        };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options) {\n        return {\n            model: this.modelName,\n            temperature: this.temperature,\n            top_p: this.topP,\n            frequency_penalty: this.frequencyPenalty,\n            presence_penalty: this.presencePenalty,\n            max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n            n: this.n,\n            logit_bias: this.logitBias,\n            stop: options?.stop ?? this.stop,\n            user: this.user,\n            stream: this.streaming,\n            functions: options?.functions ??\n                (options?.tools\n                    ? options?.tools.map(formatToOpenAIFunction)\n                    : undefined),\n            function_call: options?.function_call,\n            ...this.modelKwargs,\n        };\n    }\n    /** @ignore */\n    _identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    // TODO(jacoblee): Refactor with _generate(..., {stream: true}) implementation\n    // when we integrate OpenAI's new SDK.\n    async *_streamResponseChunks(messages, options, runManager) {\n        const messagesMapped = messages.map((message) => ({\n            role: messageToOpenAIRole(message),\n            content: message.content,\n            name: message.name,\n            function_call: message.additional_kwargs\n                .function_call,\n        }));\n        const params = {\n            ...this.invocationParams(options),\n            messages: messagesMapped,\n            stream: true,\n        };\n        let defaultRole = \"assistant\";\n        const streamIterable = this.startStream(params, options);\n        for await (const streamedResponse of streamIterable) {\n            const data = JSON.parse(streamedResponse);\n            const choice = data.choices?.[0];\n            if (!choice) {\n                continue;\n            }\n            const { delta } = choice;\n            const chunk = _convertDeltaToMessageChunk(delta, defaultRole);\n            defaultRole = (delta.role ??\n                defaultRole);\n            const generationChunk = new ChatGenerationChunk({\n                message: chunk,\n                text: chunk.content,\n            });\n            yield generationChunk;\n            // eslint-disable-next-line no-void\n            void runManager?.handleLLMNewToken(generationChunk.text ?? \"\");\n        }\n    }\n    startStream(request, options) {\n        let done = false;\n        const stream = new TransformStream();\n        const writer = stream.writable.getWriter();\n        const iterable = readableStreamToAsyncIterable(stream.readable);\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        let err;\n        this.completionWithRetry(request, {\n            ...options,\n            adapter: fetchAdapter,\n            responseType: \"stream\",\n            onmessage: (event) => {\n                if (done)\n                    return;\n                if (event.data?.trim?.() === \"[DONE]\") {\n                    done = true;\n                    // eslint-disable-next-line no-void\n                    void writer.close();\n                }\n                else {\n                    const data = JSON.parse(event.data);\n                    if (data.error) {\n                        done = true;\n                        throw data.error;\n                    }\n                    // eslint-disable-next-line no-void\n                    void writer.write(event.data);\n                }\n            },\n        }).catch((error) => {\n            if (!done) {\n                err = error;\n                done = true;\n                // eslint-disable-next-line no-void\n                void writer.close();\n            }\n        });\n        return {\n            async next() {\n                const chunk = await iterable.next();\n                if (err) {\n                    throw err;\n                }\n                return chunk;\n            },\n            [Symbol.asyncIterator]() {\n                return this;\n            },\n        };\n    }\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams() {\n        return this._identifyingParams();\n    }\n    /** @ignore */\n    async _generate(messages, options, runManager) {\n        const tokenUsage = {};\n        const params = this.invocationParams(options);\n        const messagesMapped = messages.map((message) => ({\n            role: messageToOpenAIRole(message),\n            content: message.content,\n            name: message.name,\n            function_call: message.additional_kwargs\n                .function_call,\n        }));\n        const data = params.stream\n            ? await new Promise((resolve, reject) => {\n                let response;\n                let rejected = false;\n                let resolved = false;\n                this.completionWithRetry({\n                    ...params,\n                    messages: messagesMapped,\n                }, {\n                    signal: options?.signal,\n                    ...options?.options,\n                    adapter: fetchAdapter,\n                    responseType: \"stream\",\n                    onmessage: (event) => {\n                        if (event.data?.trim?.() === \"[DONE]\") {\n                            if (resolved || rejected) {\n                                return;\n                            }\n                            resolved = true;\n                            resolve(response);\n                        }\n                        else {\n                            const data = JSON.parse(event.data);\n                            if (!data.id)\n                                return;\n                            if (data?.error) {\n                                if (rejected) {\n                                    return;\n                                }\n                                rejected = true;\n                                reject(data.error);\n                                return;\n                            }\n                            const message = data;\n                            // on the first message set the response properties\n                            if (!response) {\n                                response = {\n                                    id: message.id,\n                                    object: message.object,\n                                    created: message.created,\n                                    model: message.model,\n                                    choices: [],\n                                };\n                            }\n                            // on all messages, update choice\n                            for (const part of message.choices ?? []) {\n                                if (part != null) {\n                                    let choice = response.choices.find((c) => c.index === part.index);\n                                    if (!choice) {\n                                        choice = {\n                                            index: part.index,\n                                            finish_reason: part.finish_reason ?? undefined,\n                                        };\n                                        response.choices[part.index] = choice;\n                                    }\n                                    if (!choice.message) {\n                                        choice.message = {\n                                            role: part.delta\n                                                ?.role,\n                                            content: \"\",\n                                        };\n                                    }\n                                    if (part.delta.function_call &&\n                                        !choice.message.function_call) {\n                                        choice.message.function_call = {\n                                            name: \"\",\n                                            arguments: \"\",\n                                        };\n                                    }\n                                    choice.message.content += part.delta?.content ?? \"\";\n                                    if (choice.message.function_call) {\n                                        choice.message.function_call.name +=\n                                            part.delta?.function_call?.name ?? \"\";\n                                        choice.message.function_call.arguments +=\n                                            part.delta?.function_call?.arguments ?? \"\";\n                                    }\n                                    // eslint-disable-next-line no-void\n                                    void runManager?.handleLLMNewToken(part.delta?.content ?? \"\", {\n                                        prompt: options.promptIndex ?? 0,\n                                        completion: part.index,\n                                    });\n                                    // TODO we don't currently have a callback method for\n                                    // sending the function call arguments\n                                }\n                            }\n                            // when all messages are finished, resolve\n                            if (!resolved &&\n                                !rejected &&\n                                message.choices?.every((c) => c.finish_reason != null)) {\n                                resolved = true;\n                                resolve(response);\n                            }\n                        }\n                    },\n                }).catch((error) => {\n                    if (!rejected) {\n                        rejected = true;\n                        reject(error);\n                    }\n                });\n            })\n            : await this.completionWithRetry({\n                ...params,\n                messages: messagesMapped,\n            }, {\n                signal: options?.signal,\n                ...options?.options,\n            });\n        const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens, } = data.usage ?? {};\n        if (completionTokens) {\n            tokenUsage.completionTokens =\n                (tokenUsage.completionTokens ?? 0) + completionTokens;\n        }\n        if (promptTokens) {\n            tokenUsage.promptTokens = (tokenUsage.promptTokens ?? 0) + promptTokens;\n        }\n        if (totalTokens) {\n            tokenUsage.totalTokens = (tokenUsage.totalTokens ?? 0) + totalTokens;\n        }\n        const generations = [];\n        for (const part of data.choices) {\n            const text = part.message?.content ?? \"\";\n            generations.push({\n                text,\n                message: openAIResponseToChatMessage(part.message ?? { role: \"assistant\" }),\n            });\n        }\n        return {\n            generations,\n            llmOutput: { tokenUsage },\n        };\n    }\n    async getNumTokensFromMessages(messages) {\n        let totalCount = 0;\n        let tokensPerMessage = 0;\n        let tokensPerName = 0;\n        // From: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n        if (getModelNameForTiktoken(this.modelName) === \"gpt-3.5-turbo\") {\n            tokensPerMessage = 4;\n            tokensPerName = -1;\n        }\n        else if (getModelNameForTiktoken(this.modelName).startsWith(\"gpt-4\")) {\n            tokensPerMessage = 3;\n            tokensPerName = 1;\n        }\n        const countPerMessage = await Promise.all(messages.map(async (message) => {\n            const textCount = await this.getNumTokens(message.content);\n            const roleCount = await this.getNumTokens(messageToOpenAIRole(message));\n            const nameCount = message.name !== undefined\n                ? tokensPerName + (await this.getNumTokens(message.name))\n                : 0;\n            const count = textCount + tokensPerMessage + roleCount + nameCount;\n            totalCount += count;\n            return count;\n        }));\n        totalCount += 3; // every reply is primed with <|start|>assistant<|message|>\n        return { totalCount, countPerMessage };\n    }\n    /** @ignore */\n    async completionWithRetry(request, options) {\n        if (!this.client) {\n            const openAIEndpointConfig = {\n                azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n                azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n                azureOpenAIApiKey: this.azureOpenAIApiKey,\n                azureOpenAIBasePath: this.azureOpenAIBasePath,\n                basePath: this.clientConfig.basePath,\n            };\n            const endpoint = getEndpoint(openAIEndpointConfig);\n            const clientConfig = new Configuration({\n                ...this.clientConfig,\n                basePath: endpoint,\n                baseOptions: {\n                    timeout: this.timeout,\n                    ...this.clientConfig.baseOptions,\n                },\n            });\n            this.client = new OpenAIApi(clientConfig);\n        }\n        const axiosOptions = {\n            adapter: isNode() ? undefined : fetchAdapter,\n            ...this.clientConfig.baseOptions,\n            ...options,\n        };\n        if (this.azureOpenAIApiKey) {\n            axiosOptions.headers = {\n                \"api-key\": this.azureOpenAIApiKey,\n                ...axiosOptions.headers,\n            };\n            axiosOptions.params = {\n                \"api-version\": this.azureOpenAIApiVersion,\n                ...axiosOptions.params,\n            };\n        }\n        return this.caller\n            .call(this.client.createChatCompletion.bind(this.client), request, axiosOptions)\n            .then((res) => res.data);\n    }\n    _llmType() {\n        return \"openai\";\n    }\n    /** @ignore */\n    _combineLLMOutput(...llmOutputs) {\n        return llmOutputs.reduce((acc, llmOutput) => {\n            if (llmOutput && llmOutput.tokenUsage) {\n                acc.tokenUsage.completionTokens +=\n                    llmOutput.tokenUsage.completionTokens ?? 0;\n                acc.tokenUsage.promptTokens += llmOutput.tokenUsage.promptTokens ?? 0;\n                acc.tokenUsage.totalTokens += llmOutput.tokenUsage.totalTokens ?? 0;\n            }\n            return acc;\n        }, {\n            tokenUsage: {\n                completionTokens: 0,\n                promptTokens: 0,\n                totalTokens: 0,\n            },\n        });\n    }\n}\nexport class PromptLayerChatOpenAI extends ChatOpenAI {\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"promptLayerApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"plTags\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"returnPromptLayerId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.promptLayerApiKey =\n            fields?.promptLayerApiKey ??\n                (typeof process !== \"undefined\"\n                    ? // eslint-disable-next-line no-process-env\n                        process.env?.PROMPTLAYER_API_KEY\n                    : undefined);\n        this.plTags = fields?.plTags ?? [];\n        this.returnPromptLayerId = fields?.returnPromptLayerId ?? false;\n    }\n    async _generate(messages, options, runManager) {\n        const requestStartTime = Date.now();\n        let parsedOptions;\n        if (Array.isArray(options)) {\n            parsedOptions = { stop: options };\n        }\n        else if (options?.timeout && !options.signal) {\n            parsedOptions = {\n                ...options,\n                signal: AbortSignal.timeout(options.timeout),\n            };\n        }\n        else {\n            parsedOptions = options ?? {};\n        }\n        const generatedResponses = await super._generate(messages, parsedOptions, runManager);\n        const requestEndTime = Date.now();\n        const _convertMessageToDict = (message) => {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            let messageDict;\n            if (message._getType() === \"human\") {\n                messageDict = { role: \"user\", content: message.content };\n            }\n            else if (message._getType() === \"ai\") {\n                messageDict = { role: \"assistant\", content: message.content };\n            }\n            else if (message._getType() === \"function\") {\n                messageDict = { role: \"assistant\", content: message.content };\n            }\n            else if (message._getType() === \"system\") {\n                messageDict = { role: \"system\", content: message.content };\n            }\n            else if (message._getType() === \"generic\") {\n                messageDict = {\n                    role: message.role,\n                    content: message.content,\n                };\n            }\n            else {\n                throw new Error(`Got unknown type ${message}`);\n            }\n            return messageDict;\n        };\n        const _createMessageDicts = (messages, callOptions) => {\n            const params = {\n                ...this.invocationParams(),\n                model: this.modelName,\n            };\n            if (callOptions?.stop) {\n                if (Object.keys(params).includes(\"stop\")) {\n                    throw new Error(\"`stop` found in both the input and default params.\");\n                }\n            }\n            const messageDicts = messages.map((message) => _convertMessageToDict(message));\n            return messageDicts;\n        };\n        for (let i = 0; i < generatedResponses.generations.length; i += 1) {\n            const generation = generatedResponses.generations[i];\n            const messageDicts = _createMessageDicts(messages, parsedOptions);\n            let promptLayerRequestId;\n            const parsedResp = [\n                {\n                    content: generation.text,\n                    role: messageToOpenAIRole(generation.message),\n                },\n            ];\n            const promptLayerRespBody = await promptLayerTrackRequest(this.caller, \"langchain.PromptLayerChatOpenAI\", messageDicts, this._identifyingParams(), this.plTags, parsedResp, requestStartTime, requestEndTime, this.promptLayerApiKey);\n            if (this.returnPromptLayerId === true) {\n                if (promptLayerRespBody.success === true) {\n                    promptLayerRequestId = promptLayerRespBody.request_id;\n                }\n                if (!generation.generationInfo ||\n                    typeof generation.generationInfo !== \"object\") {\n                    generation.generationInfo = {};\n                }\n                generation.generationInfo.promptLayerRequestId = promptLayerRequestId;\n            }\n        }\n        return generatedResponses;\n    }\n}\n"],"mappings":"AAAA,SAASA,aAAa,EAAEC,SAAS,QAAS,QAAQ;AAClD,SAASC,uBAAuB,QAAQ,kCAAkC;AAC1E,SAASC,SAAS,EAAEC,cAAc,EAAEC,mBAAmB,EAAEC,WAAW,EAAEC,gBAAgB,EAAEC,oBAAoB,EAAEC,YAAY,EAAEC,iBAAiB,EAAEC,aAAa,EAAEC,kBAAkB,QAAS,oBAAoB;AAC7M,SAASC,sBAAsB,QAAQ,+BAA+B;AACtE,OAAOC,YAAY,MAAM,gCAAgC;AACzD,SAASC,WAAW,QAAQ,kBAAkB;AAC9C,SAASC,sBAAsB,EAAEC,MAAM,QAAQ,gBAAgB;AAC/D,SAASC,uBAAuB,QAAQ,yBAAyB;AACjE,SAASC,6BAA6B,QAAQ,mBAAmB;AACjE,SAASC,aAAa,QAAQ,WAAW;AACzC,SAASC,+BAA+BA,CAACC,OAAO,EAAE;EAC9C,IAAIA,OAAO,CAACC,IAAI,KAAK,QAAQ,IACzBD,OAAO,CAACC,IAAI,KAAK,WAAW,IAC5BD,OAAO,CAACC,IAAI,KAAK,MAAM,IACvBD,OAAO,CAACC,IAAI,KAAK,UAAU,EAAE;IAC7BC,OAAO,CAACC,IAAI,0BAAAC,MAAA,CAA0BJ,OAAO,CAACC,IAAI,CAAE,CAAC;EACzD;EACA,OAAOD,OAAO,CAACC,IAAI;AACvB;AACA,SAASI,mBAAmBA,CAACL,OAAO,EAAE;EAClC,MAAMM,IAAI,GAAGN,OAAO,CAACO,QAAQ,CAAC,CAAC;EAC/B,QAAQD,IAAI;IACR,KAAK,QAAQ;MACT,OAAO,QAAQ;IACnB,KAAK,IAAI;MACL,OAAO,WAAW;IACtB,KAAK,OAAO;MACR,OAAO,MAAM;IACjB,KAAK,UAAU;MACX,OAAO,UAAU;IACrB,KAAK,SAAS;MAAE;QACZ,IAAI,CAACtB,WAAW,CAACwB,UAAU,CAACR,OAAO,CAAC,EAChC,MAAM,IAAIS,KAAK,CAAC,8BAA8B,CAAC;QACnD,OAAOV,+BAA+B,CAACC,OAAO,CAAC;MACnD;IACA;MACI,MAAM,IAAIS,KAAK,0BAAAL,MAAA,CAA0BE,IAAI,CAAE,CAAC;EACxD;AACJ;AACA,SAASI,2BAA2BA,CAACV,OAAO,EAAE;EAAA,IAAAW,aAAA;EAC1C,QAAQX,OAAO,CAACC,IAAI;IAChB,KAAK,MAAM;MACP,OAAO,IAAId,YAAY,CAACa,OAAO,CAACY,OAAO,IAAI,EAAE,CAAC;IAClD,KAAK,WAAW;MACZ,OAAO,IAAI/B,SAAS,CAACmB,OAAO,CAACY,OAAO,IAAI,EAAE,EAAE;QACxCC,aAAa,EAAEb,OAAO,CAACa;MAC3B,CAAC,CAAC;IACN,KAAK,QAAQ;MACT,OAAO,IAAIxB,aAAa,CAACW,OAAO,CAACY,OAAO,IAAI,EAAE,CAAC;IACnD;MACI,OAAO,IAAI5B,WAAW,CAACgB,OAAO,CAACY,OAAO,IAAI,EAAE,GAAAD,aAAA,GAAEX,OAAO,CAACC,IAAI,cAAAU,aAAA,cAAAA,aAAA,GAAI,SAAS,CAAC;EAChF;AACJ;AACA,SAASG,2BAA2BA;AACpC;AACAC,KAAK,EAAEC,WAAW,EAAE;EAAA,IAAAC,WAAA,EAAAC,cAAA;EAChB,MAAMjB,IAAI,IAAAgB,WAAA,GAAGF,KAAK,CAACd,IAAI,cAAAgB,WAAA,cAAAA,WAAA,GAAID,WAAW;EACtC,MAAMJ,OAAO,IAAAM,cAAA,GAAGH,KAAK,CAACH,OAAO,cAAAM,cAAA,cAAAA,cAAA,GAAI,EAAE;EACnC,IAAIC,iBAAiB;EACrB,IAAIJ,KAAK,CAACF,aAAa,EAAE;IACrBM,iBAAiB,GAAG;MAChBN,aAAa,EAAEE,KAAK,CAACF;IACzB,CAAC;EACL,CAAC,MACI;IACDM,iBAAiB,GAAG,CAAC,CAAC;EAC1B;EACA,IAAIlB,IAAI,KAAK,MAAM,EAAE;IACjB,OAAO,IAAIb,iBAAiB,CAAC;MAAEwB;IAAQ,CAAC,CAAC;EAC7C,CAAC,MACI,IAAIX,IAAI,KAAK,WAAW,EAAE;IAC3B,OAAO,IAAInB,cAAc,CAAC;MAAE8B,OAAO;MAAEO;IAAkB,CAAC,CAAC;EAC7D,CAAC,MACI,IAAIlB,IAAI,KAAK,QAAQ,EAAE;IACxB,OAAO,IAAIX,kBAAkB,CAAC;MAAEsB;IAAQ,CAAC,CAAC;EAC9C,CAAC,MACI,IAAIX,IAAI,KAAK,UAAU,EAAE;IAC1B,OAAO,IAAIf,oBAAoB,CAAC;MAC5B0B,OAAO;MACPO,iBAAiB;MACjBC,IAAI,EAAEL,KAAK,CAACK;IAChB,CAAC,CAAC;EACN,CAAC,MACI;IACD,OAAO,IAAInC,gBAAgB,CAAC;MAAE2B,OAAO;MAAEX;IAAK,CAAC,CAAC;EAClD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMoB,UAAU,SAASvB,aAAa,CAAC;EAC1C,OAAOwB,OAAOA,CAAA,EAAG;IACb,OAAO,YAAY;EACvB;EACA,IAAIC,QAAQA,CAAA,EAAG;IACX,OAAO,CACH,GAAG,KAAK,CAACA,QAAQ,EACjB,SAAS,EACT,eAAe,EACf,WAAW,EACX,OAAO,EACP,aAAa,CAChB;EACL;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,YAAY,EAAE,gBAAgB;MAC9BC,iBAAiB,EAAE,sBAAsB;MACzCC,YAAY,EAAE;IAClB,CAAC;EACL;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,SAAS,EAAE,OAAO;MAClBJ,YAAY,EAAE,gBAAgB;MAC9BK,qBAAqB,EAAE,0BAA0B;MACjDJ,iBAAiB,EAAE,sBAAsB;MACzCK,0BAA0B,EAAE,gCAAgC;MAC5DC,4BAA4B,EAAE;IAClC,CAAC;EACL;EACAC,WAAWA,CAACC,MAAM,EAClB;EACAC,aAAa,EAAE;IAAA,IAAAC,oBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,sBAAA,EAAAC,sBAAA,EAAAC,qBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,iBAAA,EAAAC,mBAAA,EAAAC,mBAAA,EAAAC,YAAA,EAAAC,qBAAA,EAAAC,qBAAA,EAAAC,SAAA,EAAAC,iBAAA;IACX,KAAK,CAACjB,MAAM,aAANA,MAAM,cAANA,MAAM,GAAI,CAAC,CAAC,CAAC;IACnBkB,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,kBAAkB,EAAE;MAC5CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,GAAG,EAAE;MAC7BC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,SAAS,EAAE;MACnCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,uBAAuB,EAAE;MACjDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,mBAAmB,EAAE;MAC7CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,4BAA4B,EAAE;MACtDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,8BAA8B,EAAE;MACxDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,qBAAqB,EAAE;MAC/CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAAChC,YAAY,IAAAW,oBAAA,GACbF,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAET,YAAY,cAAAW,oBAAA,cAAAA,oBAAA,GAAI1C,sBAAsB,CAAC,gBAAgB,CAAC;IACpE,IAAI,CAACgC,iBAAiB,IAAAW,qBAAA,GAClBH,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAER,iBAAiB,cAAAW,qBAAA,cAAAA,qBAAA,GACrB3C,sBAAsB,CAAC,sBAAsB,CAAC;IACtD,IAAI,CAAC,IAAI,CAACgC,iBAAiB,IAAI,CAAC,IAAI,CAACD,YAAY,EAAE;MAC/C,MAAM,IAAIhB,KAAK,CAAC,0CAA0C,CAAC;IAC/D;IACA,IAAI,CAACsB,0BAA0B,IAAAO,sBAAA,GAC3BJ,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEH,0BAA0B,cAAAO,sBAAA,cAAAA,sBAAA,GAC9B5C,sBAAsB,CAAC,gCAAgC,CAAC;IAChE,IAAI,CAACsC,4BAA4B,IAAAO,sBAAA,GAC7BL,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEF,4BAA4B,cAAAO,sBAAA,cAAAA,sBAAA,GAChC7C,sBAAsB,CAAC,kCAAkC,CAAC;IAClE,IAAI,CAACoC,qBAAqB,IAAAU,sBAAA,GACtBN,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEJ,qBAAqB,cAAAU,sBAAA,cAAAA,sBAAA,GACzB9C,sBAAsB,CAAC,0BAA0B,CAAC;IAC1D,IAAI,CAACgE,mBAAmB,IAAAjB,qBAAA,GACpBP,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEwB,mBAAmB,cAAAjB,qBAAA,cAAAA,qBAAA,GACvB/C,sBAAsB,CAAC,wBAAwB,CAAC;IACxD,IAAI,CAACiC,YAAY,IAAAe,qBAAA,GACbR,MAAM,aAANA,MAAM,gBAAAS,sBAAA,GAANT,MAAM,CAAEC,aAAa,cAAAQ,sBAAA,uBAArBA,sBAAA,CAAuBhB,YAAY,cAAAe,qBAAA,cAAAA,qBAAA,GAC/BhD,sBAAsB,CAAC,qBAAqB,CAAC;IACrD,IAAI,CAACmC,SAAS,IAAAe,iBAAA,GAAGV,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEL,SAAS,cAAAe,iBAAA,cAAAA,iBAAA,GAAI,IAAI,CAACf,SAAS;IACpD,IAAI,CAAC8B,WAAW,IAAAd,mBAAA,GAAGX,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEyB,WAAW,cAAAd,mBAAA,cAAAA,mBAAA,GAAI,CAAC,CAAC;IAC5C,IAAI,CAACe,OAAO,GAAG1B,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE0B,OAAO;IAC9B,IAAI,CAACC,WAAW,IAAAf,mBAAA,GAAGZ,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE2B,WAAW,cAAAf,mBAAA,cAAAA,mBAAA,GAAI,IAAI,CAACe,WAAW;IAC1D,IAAI,CAACC,IAAI,IAAAf,YAAA,GAAGb,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE4B,IAAI,cAAAf,YAAA,cAAAA,YAAA,GAAI,IAAI,CAACe,IAAI;IACrC,IAAI,CAACC,gBAAgB,IAAAf,qBAAA,GAAGd,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE6B,gBAAgB,cAAAf,qBAAA,cAAAA,qBAAA,GAAI,IAAI,CAACe,gBAAgB;IACzE,IAAI,CAACC,eAAe,IAAAf,qBAAA,GAAGf,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE8B,eAAe,cAAAf,qBAAA,cAAAA,qBAAA,GAAI,IAAI,CAACe,eAAe;IACtE,IAAI,CAACC,SAAS,GAAG/B,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE+B,SAAS;IAClC,IAAI,CAACC,CAAC,IAAAhB,SAAA,GAAGhB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEgC,CAAC,cAAAhB,SAAA,cAAAA,SAAA,GAAI,IAAI,CAACgB,CAAC;IAC5B,IAAI,CAACC,SAAS,GAAGjC,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEiC,SAAS;IAClC,IAAI,CAACC,IAAI,GAAGlC,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEkC,IAAI;IACxB,IAAI,CAACC,IAAI,GAAGnC,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEmC,IAAI;IACxB,IAAI,CAACC,SAAS,IAAAnB,iBAAA,GAAGjB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEoC,SAAS,cAAAnB,iBAAA,cAAAA,iBAAA,GAAI,KAAK;IAC3C,IAAI,IAAI,CAACzB,iBAAiB,EAAE;MACxB,IAAI,CAAC,IAAI,CAACK,0BAA0B,IAAI,CAAC,IAAI,CAAC2B,mBAAmB,EAAE;QAC/D,MAAM,IAAIjD,KAAK,CAAC,0CAA0C,CAAC;MAC/D;MACA,IAAI,CAAC,IAAI,CAACuB,4BAA4B,EAAE;QACpC,MAAM,IAAIvB,KAAK,CAAC,4CAA4C,CAAC;MACjE;MACA,IAAI,CAAC,IAAI,CAACqB,qBAAqB,EAAE;QAC7B,MAAM,IAAIrB,KAAK,CAAC,oCAAoC,CAAC;MACzD;IACJ;IACA,IAAI,CAAC8D,YAAY,GAAG;MAChBC,MAAM,EAAE,IAAI,CAAC/C,YAAY;MACzBE,YAAY,EAAE,IAAI,CAACA,YAAY;MAC/B,GAAGQ,aAAa;MAChB,IAAGD,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEC,aAAa;IAC5B,CAAC;EACL;EACA;AACJ;AACA;EACIsC,gBAAgBA,CAACC,OAAO,EAAE;IAAA,IAAAC,aAAA,EAAAC,kBAAA;IACtB,OAAO;MACHC,KAAK,EAAE,IAAI,CAAChD,SAAS;MACrBgC,WAAW,EAAE,IAAI,CAACA,WAAW;MAC7BiB,KAAK,EAAE,IAAI,CAAChB,IAAI;MAChBiB,iBAAiB,EAAE,IAAI,CAAChB,gBAAgB;MACxCiB,gBAAgB,EAAE,IAAI,CAAChB,eAAe;MACtCiB,UAAU,EAAE,IAAI,CAAChB,SAAS,KAAK,CAAC,CAAC,GAAGiB,SAAS,GAAG,IAAI,CAACjB,SAAS;MAC9DC,CAAC,EAAE,IAAI,CAACA,CAAC;MACTiB,UAAU,EAAE,IAAI,CAAChB,SAAS;MAC1BC,IAAI,GAAAO,aAAA,GAAED,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEN,IAAI,cAAAO,aAAA,cAAAA,aAAA,GAAI,IAAI,CAACP,IAAI;MAChCC,IAAI,EAAE,IAAI,CAACA,IAAI;MACfe,MAAM,EAAE,IAAI,CAACd,SAAS;MACtBe,SAAS,GAAAT,kBAAA,GAAEF,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEW,SAAS,cAAAT,kBAAA,cAAAA,kBAAA,GACxBF,OAAO,aAAPA,OAAO,eAAPA,OAAO,CAAEY,KAAK,GACTZ,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEY,KAAK,CAACC,GAAG,CAAChG,sBAAsB,CAAC,GAC1C2F,SAAU;MACpBrE,aAAa,EAAE6D,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAE7D,aAAa;MACrC,GAAG,IAAI,CAAC8C;IACZ,CAAC;EACL;EACA;EACA6B,kBAAkBA,CAAA,EAAG;IACjB,OAAO;MACHC,UAAU,EAAE,IAAI,CAAC5D,SAAS;MAC1B,GAAG,IAAI,CAAC4C,gBAAgB,CAAC,CAAC;MAC1B,GAAG,IAAI,CAACF;IACZ,CAAC;EACL;EACA;EACA;EACA,OAAOmB,qBAAqBA,CAACC,QAAQ,EAAEjB,OAAO,EAAEkB,UAAU,EAAE;IACxD,MAAMC,cAAc,GAAGF,QAAQ,CAACJ,GAAG,CAAEvF,OAAO,KAAM;MAC9CC,IAAI,EAAEI,mBAAmB,CAACL,OAAO,CAAC;MAClCY,OAAO,EAAEZ,OAAO,CAACY,OAAO;MACxBQ,IAAI,EAAEpB,OAAO,CAACoB,IAAI;MAClBP,aAAa,EAAEb,OAAO,CAACmB,iBAAiB,CACnCN;IACT,CAAC,CAAC,CAAC;IACH,MAAMiF,MAAM,GAAG;MACX,GAAG,IAAI,CAACrB,gBAAgB,CAACC,OAAO,CAAC;MACjCiB,QAAQ,EAAEE,cAAc;MACxBT,MAAM,EAAE;IACZ,CAAC;IACD,IAAIpE,WAAW,GAAG,WAAW;IAC7B,MAAM+E,cAAc,GAAG,IAAI,CAACC,WAAW,CAACF,MAAM,EAAEpB,OAAO,CAAC;IACxD,WAAW,MAAMuB,gBAAgB,IAAIF,cAAc,EAAE;MAAA,IAAAG,aAAA,EAAAC,YAAA,EAAAC,qBAAA;MACjD,MAAMC,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACN,gBAAgB,CAAC;MACzC,MAAMO,MAAM,IAAAN,aAAA,GAAGG,IAAI,CAACI,OAAO,cAAAP,aAAA,uBAAZA,aAAA,CAAe,CAAC,CAAC;MAChC,IAAI,CAACM,MAAM,EAAE;QACT;MACJ;MACA,MAAM;QAAEzF;MAAM,CAAC,GAAGyF,MAAM;MACxB,MAAME,KAAK,GAAG5F,2BAA2B,CAACC,KAAK,EAAEC,WAAW,CAAC;MAC7DA,WAAW,IAAAmF,YAAA,GAAIpF,KAAK,CAACd,IAAI,cAAAkG,YAAA,cAAAA,YAAA,GACrBnF,WAAY;MAChB,MAAM2F,eAAe,GAAG,IAAI5H,mBAAmB,CAAC;QAC5CiB,OAAO,EAAE0G,KAAK;QACdE,IAAI,EAAEF,KAAK,CAAC9F;MAChB,CAAC,CAAC;MACF,MAAM+F,eAAe;MACrB;MACA,MAAKf,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEiB,iBAAiB,EAAAT,qBAAA,GAACO,eAAe,CAACC,IAAI,cAAAR,qBAAA,cAAAA,qBAAA,GAAI,EAAE,CAAC;IAClE;EACJ;EACAJ,WAAWA,CAACc,OAAO,EAAEpC,OAAO,EAAE;IAC1B,IAAIqC,IAAI,GAAG,KAAK;IAChB,MAAM3B,MAAM,GAAG,IAAI4B,eAAe,CAAC,CAAC;IACpC,MAAMC,MAAM,GAAG7B,MAAM,CAAC5B,QAAQ,CAAC0D,SAAS,CAAC,CAAC;IAC1C,MAAMC,QAAQ,GAAGtH,6BAA6B,CAACuF,MAAM,CAACgC,QAAQ,CAAC;IAC/D;IACA,IAAIC,GAAG;IACP,IAAI,CAACC,mBAAmB,CAACR,OAAO,EAAE;MAC9B,GAAGpC,OAAO;MACV6C,OAAO,EAAE/H,YAAY;MACrBgI,YAAY,EAAE,QAAQ;MACtBC,SAAS,EAAGC,KAAK,IAAK;QAAA,IAAAC,WAAA,EAAAC,gBAAA;QAClB,IAAIb,IAAI,EACJ;QACJ,IAAI,EAAAY,WAAA,GAAAD,KAAK,CAACrB,IAAI,cAAAsB,WAAA,gBAAAC,gBAAA,GAAVD,WAAA,CAAYE,IAAI,cAAAD,gBAAA,uBAAhBA,gBAAA,CAAAE,IAAA,CAAAH,WAAmB,CAAC,MAAK,QAAQ,EAAE;UACnCZ,IAAI,GAAG,IAAI;UACX;UACA,KAAKE,MAAM,CAACc,KAAK,CAAC,CAAC;QACvB,CAAC,MACI;UACD,MAAM1B,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACmB,KAAK,CAACrB,IAAI,CAAC;UACnC,IAAIA,IAAI,CAAC2B,KAAK,EAAE;YACZjB,IAAI,GAAG,IAAI;YACX,MAAMV,IAAI,CAAC2B,KAAK;UACpB;UACA;UACA,KAAKf,MAAM,CAACgB,KAAK,CAACP,KAAK,CAACrB,IAAI,CAAC;QACjC;MACJ;IACJ,CAAC,CAAC,CAAC6B,KAAK,CAAEF,KAAK,IAAK;MAChB,IAAI,CAACjB,IAAI,EAAE;QACPM,GAAG,GAAGW,KAAK;QACXjB,IAAI,GAAG,IAAI;QACX;QACA,KAAKE,MAAM,CAACc,KAAK,CAAC,CAAC;MACvB;IACJ,CAAC,CAAC;IACF,OAAO;MACH,MAAMI,IAAIA,CAAA,EAAG;QACT,MAAMzB,KAAK,GAAG,MAAMS,QAAQ,CAACgB,IAAI,CAAC,CAAC;QACnC,IAAId,GAAG,EAAE;UACL,MAAMA,GAAG;QACb;QACA,OAAOX,KAAK;MAChB,CAAC;MACD,CAAC0B,MAAM,CAACC,aAAa,IAAI;QACrB,OAAO,IAAI;MACf;IACJ,CAAC;EACL;EACA;AACJ;AACA;EACIC,iBAAiBA,CAAA,EAAG;IAChB,OAAO,IAAI,CAAC9C,kBAAkB,CAAC,CAAC;EACpC;EACA;EACA,MAAM+C,SAASA,CAAC5C,QAAQ,EAAEjB,OAAO,EAAEkB,UAAU,EAAE;IAAA,IAAA4C,WAAA;IAC3C,MAAMC,UAAU,GAAG,CAAC,CAAC;IACrB,MAAM3C,MAAM,GAAG,IAAI,CAACrB,gBAAgB,CAACC,OAAO,CAAC;IAC7C,MAAMmB,cAAc,GAAGF,QAAQ,CAACJ,GAAG,CAAEvF,OAAO,KAAM;MAC9CC,IAAI,EAAEI,mBAAmB,CAACL,OAAO,CAAC;MAClCY,OAAO,EAAEZ,OAAO,CAACY,OAAO;MACxBQ,IAAI,EAAEpB,OAAO,CAACoB,IAAI;MAClBP,aAAa,EAAEb,OAAO,CAACmB,iBAAiB,CACnCN;IACT,CAAC,CAAC,CAAC;IACH,MAAMwF,IAAI,GAAGP,MAAM,CAACV,MAAM,GACpB,MAAM,IAAIsD,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;MACrC,IAAIC,QAAQ;MACZ,IAAIC,QAAQ,GAAG,KAAK;MACpB,IAAIC,QAAQ,GAAG,KAAK;MACpB,IAAI,CAACzB,mBAAmB,CAAC;QACrB,GAAGxB,MAAM;QACTH,QAAQ,EAAEE;MACd,CAAC,EAAE;QACCmD,MAAM,EAAEtE,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEsE,MAAM;QACvB,IAAGtE,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEA,OAAO;QACnB6C,OAAO,EAAE/H,YAAY;QACrBgI,YAAY,EAAE,QAAQ;QACtBC,SAAS,EAAGC,KAAK,IAAK;UAAA,IAAAuB,YAAA,EAAAC,iBAAA;UAClB,IAAI,EAAAD,YAAA,GAAAvB,KAAK,CAACrB,IAAI,cAAA4C,YAAA,gBAAAC,iBAAA,GAAVD,YAAA,CAAYpB,IAAI,cAAAqB,iBAAA,uBAAhBA,iBAAA,CAAApB,IAAA,CAAAmB,YAAmB,CAAC,MAAK,QAAQ,EAAE;YACnC,IAAIF,QAAQ,IAAID,QAAQ,EAAE;cACtB;YACJ;YACAC,QAAQ,GAAG,IAAI;YACfJ,OAAO,CAACE,QAAQ,CAAC;UACrB,CAAC,MACI;YAAA,IAAAM,iBAAA;YACD,MAAM9C,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACmB,KAAK,CAACrB,IAAI,CAAC;YACnC,IAAI,CAACA,IAAI,CAAC+C,EAAE,EACR;YACJ,IAAI/C,IAAI,aAAJA,IAAI,eAAJA,IAAI,CAAE2B,KAAK,EAAE;cACb,IAAIc,QAAQ,EAAE;gBACV;cACJ;cACAA,QAAQ,GAAG,IAAI;cACfF,MAAM,CAACvC,IAAI,CAAC2B,KAAK,CAAC;cAClB;YACJ;YACA,MAAMhI,OAAO,GAAGqG,IAAI;YACpB;YACA,IAAI,CAACwC,QAAQ,EAAE;cACXA,QAAQ,GAAG;gBACPO,EAAE,EAAEpJ,OAAO,CAACoJ,EAAE;gBACdC,MAAM,EAAErJ,OAAO,CAACqJ,MAAM;gBACtBC,OAAO,EAAEtJ,OAAO,CAACsJ,OAAO;gBACxBzE,KAAK,EAAE7E,OAAO,CAAC6E,KAAK;gBACpB4B,OAAO,EAAE;cACb,CAAC;YACL;YACA;YACA,KAAK,MAAM8C,IAAI,KAAAC,gBAAA,GAAIxJ,OAAO,CAACyG,OAAO,cAAA+C,gBAAA,cAAAA,gBAAA,GAAI,EAAE,EAAE;cAAA,IAAAA,gBAAA;cACtC,IAAID,IAAI,IAAI,IAAI,EAAE;gBAAA,IAAAE,mBAAA,EAAAC,YAAA,EAAAC,oBAAA,EAAAC,YAAA,EAAAC,oBAAA;gBACd,IAAIrD,MAAM,GAAGqC,QAAQ,CAACpC,OAAO,CAACqD,IAAI,CAAEC,CAAC,IAAKA,CAAC,CAACC,KAAK,KAAKT,IAAI,CAACS,KAAK,CAAC;gBACjE,IAAI,CAACxD,MAAM,EAAE;kBAAA,IAAAyD,mBAAA;kBACTzD,MAAM,GAAG;oBACLwD,KAAK,EAAET,IAAI,CAACS,KAAK;oBACjBE,aAAa,GAAAD,mBAAA,GAAEV,IAAI,CAACW,aAAa,cAAAD,mBAAA,cAAAA,mBAAA,GAAI/E;kBACzC,CAAC;kBACD2D,QAAQ,CAACpC,OAAO,CAAC8C,IAAI,CAACS,KAAK,CAAC,GAAGxD,MAAM;gBACzC;gBACA,IAAI,CAACA,MAAM,CAACxG,OAAO,EAAE;kBAAA,IAAAmK,WAAA;kBACjB3D,MAAM,CAACxG,OAAO,GAAG;oBACbC,IAAI,GAAAkK,WAAA,GAAEZ,IAAI,CAACxI,KAAK,cAAAoJ,WAAA,uBAAVA,WAAA,CACAlK,IAAI;oBACVW,OAAO,EAAE;kBACb,CAAC;gBACL;gBACA,IAAI2I,IAAI,CAACxI,KAAK,CAACF,aAAa,IACxB,CAAC2F,MAAM,CAACxG,OAAO,CAACa,aAAa,EAAE;kBAC/B2F,MAAM,CAACxG,OAAO,CAACa,aAAa,GAAG;oBAC3BO,IAAI,EAAE,EAAE;oBACRgJ,SAAS,EAAE;kBACf,CAAC;gBACL;gBACA5D,MAAM,CAACxG,OAAO,CAACY,OAAO,KAAA6I,mBAAA,IAAAC,YAAA,GAAIH,IAAI,CAACxI,KAAK,cAAA2I,YAAA,uBAAVA,YAAA,CAAY9I,OAAO,cAAA6I,mBAAA,cAAAA,mBAAA,GAAI,EAAE;gBACnD,IAAIjD,MAAM,CAACxG,OAAO,CAACa,aAAa,EAAE;kBAAA,IAAAwJ,qBAAA,EAAAC,YAAA,EAAAC,sBAAA,EAAAC,YAAA;kBAC9BhE,MAAM,CAACxG,OAAO,CAACa,aAAa,CAACO,IAAI,KAAAiJ,qBAAA,IAAAC,YAAA,GAC7Bf,IAAI,CAACxI,KAAK,cAAAuJ,YAAA,gBAAAA,YAAA,GAAVA,YAAA,CAAYzJ,aAAa,cAAAyJ,YAAA,uBAAzBA,YAAA,CAA2BlJ,IAAI,cAAAiJ,qBAAA,cAAAA,qBAAA,GAAI,EAAE;kBACzC7D,MAAM,CAACxG,OAAO,CAACa,aAAa,CAACuJ,SAAS,KAAAG,sBAAA,IAAAC,YAAA,GAClCjB,IAAI,CAACxI,KAAK,cAAAyJ,YAAA,gBAAAA,YAAA,GAAVA,YAAA,CAAY3J,aAAa,cAAA2J,YAAA,uBAAzBA,YAAA,CAA2BJ,SAAS,cAAAG,sBAAA,cAAAA,sBAAA,GAAI,EAAE;gBAClD;gBACA;gBACA,MAAK3E,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEiB,iBAAiB,EAAA8C,oBAAA,IAAAC,YAAA,GAACL,IAAI,CAACxI,KAAK,cAAA6I,YAAA,uBAAVA,YAAA,CAAYhJ,OAAO,cAAA+I,oBAAA,cAAAA,oBAAA,GAAI,EAAE,EAAE;kBAC1Dc,MAAM,GAAAZ,oBAAA,GAAEnF,OAAO,CAACgG,WAAW,cAAAb,oBAAA,cAAAA,oBAAA,GAAI,CAAC;kBAChCc,UAAU,EAAEpB,IAAI,CAACS;gBACrB,CAAC,CAAC;gBACF;gBACA;cACJ;YACJ;YACA;YACA,IAAI,CAACjB,QAAQ,IACT,CAACD,QAAQ,KAAAK,iBAAA,GACTnJ,OAAO,CAACyG,OAAO,cAAA0C,iBAAA,eAAfA,iBAAA,CAAiByB,KAAK,CAAEb,CAAC,IAAKA,CAAC,CAACG,aAAa,IAAI,IAAI,CAAC,EAAE;cACxDnB,QAAQ,GAAG,IAAI;cACfJ,OAAO,CAACE,QAAQ,CAAC;YACrB;UACJ;QACJ;MACJ,CAAC,CAAC,CAACX,KAAK,CAAEF,KAAK,IAAK;QAChB,IAAI,CAACc,QAAQ,EAAE;UACXA,QAAQ,GAAG,IAAI;UACfF,MAAM,CAACZ,KAAK,CAAC;QACjB;MACJ,CAAC,CAAC;IACN,CAAC,CAAC,GACA,MAAM,IAAI,CAACV,mBAAmB,CAAC;MAC7B,GAAGxB,MAAM;MACTH,QAAQ,EAAEE;IACd,CAAC,EAAE;MACCmD,MAAM,EAAEtE,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEsE,MAAM;MACvB,IAAGtE,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEA,OAAO;IACvB,CAAC,CAAC;IACN,MAAM;MAAEmG,iBAAiB,EAAEC,gBAAgB;MAAEC,aAAa,EAAEC,YAAY;MAAEC,YAAY,EAAEC;IAAa,CAAC,IAAA1C,WAAA,GAAGnC,IAAI,CAAC8E,KAAK,cAAA3C,WAAA,cAAAA,WAAA,GAAI,CAAC,CAAC;IACzH,IAAIsC,gBAAgB,EAAE;MAAA,IAAAM,qBAAA;MAClB3C,UAAU,CAACqC,gBAAgB,GACvB,EAAAM,qBAAA,GAAC3C,UAAU,CAACqC,gBAAgB,cAAAM,qBAAA,cAAAA,qBAAA,GAAI,CAAC,IAAIN,gBAAgB;IAC7D;IACA,IAAIE,YAAY,EAAE;MAAA,IAAAK,qBAAA;MACd5C,UAAU,CAACuC,YAAY,GAAG,EAAAK,qBAAA,GAAC5C,UAAU,CAACuC,YAAY,cAAAK,qBAAA,cAAAA,qBAAA,GAAI,CAAC,IAAIL,YAAY;IAC3E;IACA,IAAIE,WAAW,EAAE;MAAA,IAAAI,qBAAA;MACb7C,UAAU,CAACyC,WAAW,GAAG,EAAAI,qBAAA,GAAC7C,UAAU,CAACyC,WAAW,cAAAI,qBAAA,cAAAA,qBAAA,GAAI,CAAC,IAAIJ,WAAW;IACxE;IACA,MAAMK,WAAW,GAAG,EAAE;IACtB,KAAK,MAAMhC,IAAI,IAAIlD,IAAI,CAACI,OAAO,EAAE;MAAA,IAAA+E,qBAAA,EAAAC,aAAA,EAAAC,cAAA;MAC7B,MAAM9E,IAAI,IAAA4E,qBAAA,IAAAC,aAAA,GAAGlC,IAAI,CAACvJ,OAAO,cAAAyL,aAAA,uBAAZA,aAAA,CAAc7K,OAAO,cAAA4K,qBAAA,cAAAA,qBAAA,GAAI,EAAE;MACxCD,WAAW,CAACI,IAAI,CAAC;QACb/E,IAAI;QACJ5G,OAAO,EAAEU,2BAA2B,EAAAgL,cAAA,GAACnC,IAAI,CAACvJ,OAAO,cAAA0L,cAAA,cAAAA,cAAA,GAAI;UAAEzL,IAAI,EAAE;QAAY,CAAC;MAC9E,CAAC,CAAC;IACN;IACA,OAAO;MACHsL,WAAW;MACXK,SAAS,EAAE;QAAEnD;MAAW;IAC5B,CAAC;EACL;EACA,MAAMoD,wBAAwBA,CAAClG,QAAQ,EAAE;IACrC,IAAImG,UAAU,GAAG,CAAC;IAClB,IAAIC,gBAAgB,GAAG,CAAC;IACxB,IAAIC,aAAa,GAAG,CAAC;IACrB;IACA,IAAIpN,uBAAuB,CAAC,IAAI,CAACiD,SAAS,CAAC,KAAK,eAAe,EAAE;MAC7DkK,gBAAgB,GAAG,CAAC;MACpBC,aAAa,GAAG,CAAC,CAAC;IACtB,CAAC,MACI,IAAIpN,uBAAuB,CAAC,IAAI,CAACiD,SAAS,CAAC,CAACoK,UAAU,CAAC,OAAO,CAAC,EAAE;MAClEF,gBAAgB,GAAG,CAAC;MACpBC,aAAa,GAAG,CAAC;IACrB;IACA,MAAME,eAAe,GAAG,MAAMxD,OAAO,CAACyD,GAAG,CAACxG,QAAQ,CAACJ,GAAG,CAAC,MAAOvF,OAAO,IAAK;MACtE,MAAMoM,SAAS,GAAG,MAAM,IAAI,CAACC,YAAY,CAACrM,OAAO,CAACY,OAAO,CAAC;MAC1D,MAAM0L,SAAS,GAAG,MAAM,IAAI,CAACD,YAAY,CAAChM,mBAAmB,CAACL,OAAO,CAAC,CAAC;MACvE,MAAMuM,SAAS,GAAGvM,OAAO,CAACoB,IAAI,KAAK8D,SAAS,GACtC8G,aAAa,IAAI,MAAM,IAAI,CAACK,YAAY,CAACrM,OAAO,CAACoB,IAAI,CAAC,CAAC,GACvD,CAAC;MACP,MAAMoL,KAAK,GAAGJ,SAAS,GAAGL,gBAAgB,GAAGO,SAAS,GAAGC,SAAS;MAClET,UAAU,IAAIU,KAAK;MACnB,OAAOA,KAAK;IAChB,CAAC,CAAC,CAAC;IACHV,UAAU,IAAI,CAAC,CAAC,CAAC;IACjB,OAAO;MAAEA,UAAU;MAAEI;IAAgB,CAAC;EAC1C;EACA;EACA,MAAM5E,mBAAmBA,CAACR,OAAO,EAAEpC,OAAO,EAAE;IACxC,IAAI,CAAC,IAAI,CAAC+H,MAAM,EAAE;MACd,MAAMC,oBAAoB,GAAG;QACzB1K,4BAA4B,EAAE,IAAI,CAACA,4BAA4B;QAC/DD,0BAA0B,EAAE,IAAI,CAACA,0BAA0B;QAC3DL,iBAAiB,EAAE,IAAI,CAACA,iBAAiB;QACzCgC,mBAAmB,EAAE,IAAI,CAACA,mBAAmB;QAC7CiJ,QAAQ,EAAE,IAAI,CAACpI,YAAY,CAACoI;MAChC,CAAC;MACD,MAAMC,QAAQ,GAAGnN,WAAW,CAACiN,oBAAoB,CAAC;MAClD,MAAMnI,YAAY,GAAG,IAAI7F,aAAa,CAAC;QACnC,GAAG,IAAI,CAAC6F,YAAY;QACpBoI,QAAQ,EAAEC,QAAQ;QAClBC,WAAW,EAAE;UACTjJ,OAAO,EAAE,IAAI,CAACA,OAAO;UACrB,GAAG,IAAI,CAACW,YAAY,CAACsI;QACzB;MACJ,CAAC,CAAC;MACF,IAAI,CAACJ,MAAM,GAAG,IAAI9N,SAAS,CAAC4F,YAAY,CAAC;IAC7C;IACA,MAAMuI,YAAY,GAAG;MACjBvF,OAAO,EAAE5H,MAAM,CAAC,CAAC,GAAGuF,SAAS,GAAG1F,YAAY;MAC5C,GAAG,IAAI,CAAC+E,YAAY,CAACsI,WAAW;MAChC,GAAGnI;IACP,CAAC;IACD,IAAI,IAAI,CAAChD,iBAAiB,EAAE;MACxBoL,YAAY,CAACC,OAAO,GAAG;QACnB,SAAS,EAAE,IAAI,CAACrL,iBAAiB;QACjC,GAAGoL,YAAY,CAACC;MACpB,CAAC;MACDD,YAAY,CAAChH,MAAM,GAAG;QAClB,aAAa,EAAE,IAAI,CAAChE,qBAAqB;QACzC,GAAGgL,YAAY,CAAChH;MACpB,CAAC;IACL;IACA,OAAO,IAAI,CAACkH,MAAM,CACblF,IAAI,CAAC,IAAI,CAAC2E,MAAM,CAACQ,oBAAoB,CAACC,IAAI,CAAC,IAAI,CAACT,MAAM,CAAC,EAAE3F,OAAO,EAAEgG,YAAY,CAAC,CAC/EK,IAAI,CAAEC,GAAG,IAAKA,GAAG,CAAC/G,IAAI,CAAC;EAChC;EACAgH,QAAQA,CAAA,EAAG;IACP,OAAO,QAAQ;EACnB;EACA;EACAC,iBAAiBA,CAAA,EAAgB;IAAA,SAAAC,IAAA,GAAAnD,SAAA,CAAAoD,MAAA,EAAZC,UAAU,OAAAC,KAAA,CAAAH,IAAA,GAAAI,IAAA,MAAAA,IAAA,GAAAJ,IAAA,EAAAI,IAAA;MAAVF,UAAU,CAAAE,IAAA,IAAAvD,SAAA,CAAAuD,IAAA;IAAA;IAC3B,OAAOF,UAAU,CAACG,MAAM,CAAC,CAACC,GAAG,EAAEjC,SAAS,KAAK;MACzC,IAAIA,SAAS,IAAIA,SAAS,CAACnD,UAAU,EAAE;QAAA,IAAAqF,qBAAA,EAAAC,sBAAA,EAAAC,sBAAA;QACnCH,GAAG,CAACpF,UAAU,CAACqC,gBAAgB,KAAAgD,qBAAA,GAC3BlC,SAAS,CAACnD,UAAU,CAACqC,gBAAgB,cAAAgD,qBAAA,cAAAA,qBAAA,GAAI,CAAC;QAC9CD,GAAG,CAACpF,UAAU,CAACuC,YAAY,KAAA+C,sBAAA,GAAInC,SAAS,CAACnD,UAAU,CAACuC,YAAY,cAAA+C,sBAAA,cAAAA,sBAAA,GAAI,CAAC;QACrEF,GAAG,CAACpF,UAAU,CAACyC,WAAW,KAAA8C,sBAAA,GAAIpC,SAAS,CAACnD,UAAU,CAACyC,WAAW,cAAA8C,sBAAA,cAAAA,sBAAA,GAAI,CAAC;MACvE;MACA,OAAOH,GAAG;IACd,CAAC,EAAE;MACCpF,UAAU,EAAE;QACRqC,gBAAgB,EAAE,CAAC;QACnBE,YAAY,EAAE,CAAC;QACfE,WAAW,EAAE;MACjB;IACJ,CAAC,CAAC;EACN;AACJ;AACA,OAAO,MAAM+C,qBAAqB,SAAS5M,UAAU,CAAC;EAClDY,WAAWA,CAACC,MAAM,EAAE;IAAA,IAAAgM,qBAAA,EAAAC,YAAA,EAAAC,cAAA,EAAAC,qBAAA;IAChB,KAAK,CAACnM,MAAM,CAAC;IACbkB,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,mBAAmB,EAAE;MAC7CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,qBAAqB,EAAE;MAC/CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAAC6K,iBAAiB,IAAAJ,qBAAA,GAClBhM,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEoM,iBAAiB,cAAAJ,qBAAA,cAAAA,qBAAA,GACpB,OAAOK,OAAO,KAAK,WAAW,GACzB;IAAA,CAAAJ,YAAA,GACEI,OAAO,CAACC,GAAG,cAAAL,YAAA,uBAAXA,YAAA,CAAaM,mBAAmB,GAClCvJ,SAAU;IACxB,IAAI,CAACwJ,MAAM,IAAAN,cAAA,GAAGlM,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEwM,MAAM,cAAAN,cAAA,cAAAA,cAAA,GAAI,EAAE;IAClC,IAAI,CAACO,mBAAmB,IAAAN,qBAAA,GAAGnM,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEyM,mBAAmB,cAAAN,qBAAA,cAAAA,qBAAA,GAAI,KAAK;EACnE;EACA,MAAM9F,SAASA,CAAC5C,QAAQ,EAAEjB,OAAO,EAAEkB,UAAU,EAAE;IAC3C,MAAMgJ,gBAAgB,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;IACnC,IAAIC,aAAa;IACjB,IAAIrB,KAAK,CAACsB,OAAO,CAACtK,OAAO,CAAC,EAAE;MACxBqK,aAAa,GAAG;QAAE3K,IAAI,EAAEM;MAAQ,CAAC;IACrC,CAAC,MACI,IAAIA,OAAO,aAAPA,OAAO,eAAPA,OAAO,CAAEd,OAAO,IAAI,CAACc,OAAO,CAACsE,MAAM,EAAE;MAC1C+F,aAAa,GAAG;QACZ,GAAGrK,OAAO;QACVsE,MAAM,EAAEiG,WAAW,CAACrL,OAAO,CAACc,OAAO,CAACd,OAAO;MAC/C,CAAC;IACL,CAAC,MACI;MACDmL,aAAa,GAAGrK,OAAO,aAAPA,OAAO,cAAPA,OAAO,GAAI,CAAC,CAAC;IACjC;IACA,MAAMwK,kBAAkB,GAAG,MAAM,KAAK,CAAC3G,SAAS,CAAC5C,QAAQ,EAAEoJ,aAAa,EAAEnJ,UAAU,CAAC;IACrF,MAAMuJ,cAAc,GAAGN,IAAI,CAACC,GAAG,CAAC,CAAC;IACjC,MAAMM,qBAAqB,GAAIpP,OAAO,IAAK;MACvC;MACA,IAAIqP,WAAW;MACf,IAAIrP,OAAO,CAACO,QAAQ,CAAC,CAAC,KAAK,OAAO,EAAE;QAChC8O,WAAW,GAAG;UAAEpP,IAAI,EAAE,MAAM;UAAEW,OAAO,EAAEZ,OAAO,CAACY;QAAQ,CAAC;MAC5D,CAAC,MACI,IAAIZ,OAAO,CAACO,QAAQ,CAAC,CAAC,KAAK,IAAI,EAAE;QAClC8O,WAAW,GAAG;UAAEpP,IAAI,EAAE,WAAW;UAAEW,OAAO,EAAEZ,OAAO,CAACY;QAAQ,CAAC;MACjE,CAAC,MACI,IAAIZ,OAAO,CAACO,QAAQ,CAAC,CAAC,KAAK,UAAU,EAAE;QACxC8O,WAAW,GAAG;UAAEpP,IAAI,EAAE,WAAW;UAAEW,OAAO,EAAEZ,OAAO,CAACY;QAAQ,CAAC;MACjE,CAAC,MACI,IAAIZ,OAAO,CAACO,QAAQ,CAAC,CAAC,KAAK,QAAQ,EAAE;QACtC8O,WAAW,GAAG;UAAEpP,IAAI,EAAE,QAAQ;UAAEW,OAAO,EAAEZ,OAAO,CAACY;QAAQ,CAAC;MAC9D,CAAC,MACI,IAAIZ,OAAO,CAACO,QAAQ,CAAC,CAAC,KAAK,SAAS,EAAE;QACvC8O,WAAW,GAAG;UACVpP,IAAI,EAAED,OAAO,CAACC,IAAI;UAClBW,OAAO,EAAEZ,OAAO,CAACY;QACrB,CAAC;MACL,CAAC,MACI;QACD,MAAM,IAAIH,KAAK,qBAAAL,MAAA,CAAqBJ,OAAO,CAAE,CAAC;MAClD;MACA,OAAOqP,WAAW;IACtB,CAAC;IACD,MAAMC,mBAAmB,GAAGA,CAAC3J,QAAQ,EAAE4J,WAAW,KAAK;MACnD,MAAMzJ,MAAM,GAAG;QACX,GAAG,IAAI,CAACrB,gBAAgB,CAAC,CAAC;QAC1BI,KAAK,EAAE,IAAI,CAAChD;MAChB,CAAC;MACD,IAAI0N,WAAW,aAAXA,WAAW,eAAXA,WAAW,CAAEnL,IAAI,EAAE;QACnB,IAAIhB,MAAM,CAACoM,IAAI,CAAC1J,MAAM,CAAC,CAAC2J,QAAQ,CAAC,MAAM,CAAC,EAAE;UACtC,MAAM,IAAIhP,KAAK,CAAC,oDAAoD,CAAC;QACzE;MACJ;MACA,MAAMiP,YAAY,GAAG/J,QAAQ,CAACJ,GAAG,CAAEvF,OAAO,IAAKoP,qBAAqB,CAACpP,OAAO,CAAC,CAAC;MAC9E,OAAO0P,YAAY;IACvB,CAAC;IACD,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGT,kBAAkB,CAAC3D,WAAW,CAACiC,MAAM,EAAEmC,CAAC,IAAI,CAAC,EAAE;MAC/D,MAAMC,UAAU,GAAGV,kBAAkB,CAAC3D,WAAW,CAACoE,CAAC,CAAC;MACpD,MAAMD,YAAY,GAAGJ,mBAAmB,CAAC3J,QAAQ,EAAEoJ,aAAa,CAAC;MACjE,IAAIc,oBAAoB;MACxB,MAAMC,UAAU,GAAG,CACf;QACIlP,OAAO,EAAEgP,UAAU,CAAChJ,IAAI;QACxB3G,IAAI,EAAEI,mBAAmB,CAACuP,UAAU,CAAC5P,OAAO;MAChD,CAAC,CACJ;MACD,MAAM+P,mBAAmB,GAAG,MAAMnQ,uBAAuB,CAAC,IAAI,CAACoN,MAAM,EAAE,iCAAiC,EAAE0C,YAAY,EAAE,IAAI,CAAClK,kBAAkB,CAAC,CAAC,EAAE,IAAI,CAACkJ,MAAM,EAAEoB,UAAU,EAAElB,gBAAgB,EAAEO,cAAc,EAAE,IAAI,CAACb,iBAAiB,CAAC;MACrO,IAAI,IAAI,CAACK,mBAAmB,KAAK,IAAI,EAAE;QACnC,IAAIoB,mBAAmB,CAACC,OAAO,KAAK,IAAI,EAAE;UACtCH,oBAAoB,GAAGE,mBAAmB,CAACE,UAAU;QACzD;QACA,IAAI,CAACL,UAAU,CAACM,cAAc,IAC1B,OAAON,UAAU,CAACM,cAAc,KAAK,QAAQ,EAAE;UAC/CN,UAAU,CAACM,cAAc,GAAG,CAAC,CAAC;QAClC;QACAN,UAAU,CAACM,cAAc,CAACL,oBAAoB,GAAGA,oBAAoB;MACzE;IACJ;IACA,OAAOX,kBAAkB;EAC7B;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}